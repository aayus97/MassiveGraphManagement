{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "356d5add-318c-486b-a967-4a19ed651b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import RGCNConv, Node2Vec\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3e1ac77c-55f3-4536-ba94-0aa147ea9b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch-geometric -f https://data.pyg.org/whl/torch-2.5.1+cpu.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "325acb82-bfe8-444e-8678-0e8128f14b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pyg-lib torch-scatter torch-sparse torch-cluster -f https://data.pyg.org/whl/torch-2.5.1+cpu.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f143442e-5989-4ded-955b-a1a2bdebaef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f518b51e-b384-447e-913c-8ef54141bd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Final Triples DataFrame ###\n",
      "              Subject          Predicate             Object\n",
      "0        Patient_S_29   hasDiseaseStatus    sepsis survivor\n",
      "1        Patient_S_29          hasSample  Sample_GSM1317945\n",
      "2   Sample_GSM1317945  hasGeneExpression         Gene_60496\n",
      "3   Sample_GSM1317945  hasGeneExpression            Gene_18\n",
      "4   Sample_GSM1317945  hasGeneExpression         Gene_10347\n",
      "5   Sample_GSM1317945  hasGeneExpression           Gene_215\n",
      "6   Sample_GSM1317945  hasGeneExpression            Gene_23\n",
      "7   Sample_GSM1317945  hasGeneExpression            Gene_26\n",
      "8   Sample_GSM1317945  hasGeneExpression         Gene_27034\n",
      "9   Sample_GSM1317945  hasGeneExpression            Gene_37\n",
      "10  Sample_GSM1317945  hasGeneExpression         Gene_91452\n",
      "11  Sample_GSM1317945  hasGeneExpression         Gene_22985\n",
      "12  Sample_GSM1317945  hasGeneExpression            Gene_51\n",
      "13  Sample_GSM1317945  hasGeneExpression          Gene_2180\n",
      "14  Sample_GSM1317945  hasGeneExpression         Gene_84532\n",
      "15  Sample_GSM1317945  hasGeneExpression            Gene_60\n",
      "16  Sample_GSM1317945  hasGeneExpression            Gene_71\n",
      "17  Sample_GSM1317945  hasGeneExpression            Gene_81\n",
      "18  Sample_GSM1317945  hasGeneExpression         Gene_10096\n",
      "19  Sample_GSM1317945  hasGeneExpression            Gene_90\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import get_ontology\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the ontology\n",
    "ontology_path = \"enriched_ppio_ontology_final_54_small.owl\"  # Replace with your OWL file path\n",
    "ontology = get_ontology(ontology_path).load()\n",
    "\n",
    "# Step 2: Extract triples for patients with disease statuses and their relationships\n",
    "def extract_patient_triples(ontology, target_statuses, relations_of_interest):\n",
    "    \"\"\"\n",
    "    Extract triples (subject, predicate, object) for patients with specific disease statuses\n",
    "    and related properties like hasSample, isAssociatedWithPathway, hasGeneExpression.\n",
    "    \"\"\"\n",
    "    triples = []\n",
    "\n",
    "    # Iterate through all individuals in the ontology\n",
    "    for patient in ontology.individuals():\n",
    "        if \"Patient\" in [cls.name for cls in patient.is_a]:  # Filter only Patient instances\n",
    "            disease_status = None\n",
    "            samples = []\n",
    "\n",
    "            # Extract properties of the patient\n",
    "            for prop in patient.get_properties():\n",
    "                for value in prop[patient]:\n",
    "                    if prop.python_name == \"hasDiseaseStatus\":\n",
    "                        disease_status = value\n",
    "                    elif prop.python_name == \"hasSample\":\n",
    "                        samples.append(value.name)\n",
    "\n",
    "            # If the patient matches the target disease status\n",
    "            if disease_status in target_statuses:\n",
    "                triples.append((patient.name, \"hasDiseaseStatus\", disease_status))\n",
    "\n",
    "                # Extract relationships for associated samples\n",
    "                for sample_name in samples:\n",
    "                    triples.append((patient.name, \"hasSample\", sample_name))\n",
    "                    # Find relationships for the sample\n",
    "                    for sample in ontology.individuals():\n",
    "                        if sample.name == sample_name:\n",
    "                            for prop in sample.get_properties():\n",
    "                                if prop.python_name in relations_of_interest:\n",
    "                                    for value in prop[sample]:\n",
    "                                        if hasattr(value, 'name'):\n",
    "                                            triples.append((sample.name, prop.python_name, value.name))\n",
    "\n",
    "    return triples\n",
    "\n",
    "# Step 3: Define disease statuses and relationships of interest\n",
    "target_statuses = [\"sepsis survivor\", \"sepsis non-survivor\"]\n",
    "relations_of_interest = [\"isAssociatedWithPathway\", \"hasGeneExpression\"]\n",
    "\n",
    "# Step 4: Extract triples\n",
    "triples = extract_patient_triples(ontology, target_statuses, relations_of_interest)\n",
    "\n",
    "# Step 5: Convert to DataFrame and remove duplicates\n",
    "triples_df1 = pd.DataFrame(triples, columns=[\"Subject\", \"Predicate\", \"Object\"]).drop_duplicates()\n",
    "\n",
    "# Step 6: Display the results\n",
    "print(\"\\n### Final Triples DataFrame ###\")\n",
    "print(triples_df1.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3ae85e-689d-4c77-a5fb-94a0d8d21ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fb341840-ab39-48c7-add3-369788e4e4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Extracted Gene Triples ###\n",
      "       Subject                Predicate                 Object\n",
      "0   Gene_60496  isAssociatedWithPathway        Pathway_0000000\n",
      "1   Gene_60496  isAssociatedWithPathway  Pathway_R-HSA-1430728\n",
      "2   Gene_60496  isAssociatedWithPathway   Pathway_R-HSA-196849\n",
      "3   Gene_60496  isAssociatedWithPathway   Pathway_R-HSA-196854\n",
      "4      Gene_18  isAssociatedWithPathway        Pathway_0000000\n",
      "5      Gene_18  isAssociatedWithPathway   Pathway_R-HSA-112315\n",
      "6      Gene_18  isAssociatedWithPathway   Pathway_R-HSA-112316\n",
      "7   Gene_10347  isAssociatedWithPathway        Pathway_0000000\n",
      "8   Gene_10347  isAssociatedWithPathway   Pathway_R-HSA-382551\n",
      "9     Gene_215  isAssociatedWithPathway        Pathway_0000000\n",
      "10    Gene_215  isAssociatedWithPathway  Pathway_R-HSA-1643685\n",
      "11    Gene_215  isAssociatedWithPathway  Pathway_R-HSA-1430728\n",
      "12    Gene_215  isAssociatedWithPathway   Pathway_R-HSA-556833\n",
      "13    Gene_215  isAssociatedWithPathway   Pathway_R-HSA-382551\n",
      "14    Gene_215  isAssociatedWithPathway  Pathway_R-HSA-9609507\n",
      "15    Gene_215  isAssociatedWithPathway  Pathway_R-HSA-5619115\n",
      "16    Gene_215  isAssociatedWithPathway  Pathway_R-HSA-8978868\n",
      "17     Gene_23  isAssociatedWithPathway        Pathway_0000000\n",
      "18     Gene_23  isAssociatedWithPathway   Pathway_R-HSA-382551\n",
      "19     Gene_26  isAssociatedWithPathway        Pathway_0000000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 2: Extract relevant triples\n",
    "def extract_gene_triples(ontology, relations_of_interest):\n",
    "    \"\"\"\n",
    "    Extract triples (subject, predicate, object) for genes with specific relationships.\n",
    "    \"\"\"\n",
    "    triples = []\n",
    "\n",
    "    # Iterate through individuals in the ontology\n",
    "    for entity in ontology.individuals():\n",
    "        # Process only Gene entities\n",
    "        if \"Gene\" in [cls.name for cls in entity.is_a]:\n",
    "            for prop in entity.get_properties():\n",
    "                # Match properties of interest\n",
    "                if prop.python_name in relations_of_interest:\n",
    "                    for value in prop[entity]:\n",
    "                        if hasattr(value, 'name'):  # Check if value is another entity\n",
    "                            triples.append((entity.name, prop.python_name, value.name))\n",
    "    return triples\n",
    "\n",
    "# Step 3: Define relationships of interest\n",
    "relations_of_interest = [\n",
    " \"isAssociatedWithPathway\"\n",
    "]\n",
    "\n",
    "# Step 4: Extract triples\n",
    "gene_triples = extract_gene_triples(ontology, relations_of_interest)\n",
    "\n",
    "# Step 5: Convert to DataFrame\n",
    "triples_df2 = pd.DataFrame(gene_triples, columns=[\"Subject\", \"Predicate\", \"Object\"])\n",
    "\n",
    "# Step 6: Display the triples\n",
    "print(\"\\n### Extracted Gene Triples ###\")\n",
    "print(triples_df2.head(20))  # Display the first 20 rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "29edad09-f0c3-4582-a53d-26e82d5fd416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Combined Triples DataFrame ###\n",
      "                  Subject                Predicate                Object\n",
      "0            Patient_S_29         hasDiseaseStatus       sepsis survivor\n",
      "1            Patient_S_29                hasSample     Sample_GSM1317945\n",
      "2       Sample_GSM1317945        hasGeneExpression            Gene_60496\n",
      "3       Sample_GSM1317945        hasGeneExpression               Gene_18\n",
      "4       Sample_GSM1317945        hasGeneExpression            Gene_10347\n",
      "...                   ...                      ...                   ...\n",
      "144851        Gene_170960  isAssociatedWithPathway  Pathway_R-HSA-212436\n",
      "144852        Gene_155061  isAssociatedWithPathway       Pathway_0000000\n",
      "144853        Gene_155061  isAssociatedWithPathway   Pathway_R-HSA-74160\n",
      "144854        Gene_155061  isAssociatedWithPathway   Pathway_R-HSA-73857\n",
      "144855        Gene_155061  isAssociatedWithPathway  Pathway_R-HSA-212436\n",
      "\n",
      "[144856 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Concatenate the two DataFrames\n",
    "combined_df = pd.concat([triples_df1, triples_df2], ignore_index=True)\n",
    "\n",
    "# Step 2: Display the combined DataFrame\n",
    "print(\"\\n### Combined Triples DataFrame ###\")\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93237cc-7d0f-4eed-824b-8c5f6327f5bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eaffd8-a2dd-4dd8-bd16-f5cacef56d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd1550b-0b93-41bf-badc-5d0a21fdf6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ba30e-c44e-454f-bf07-cfd94c513bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f06283-b857-4e76-9b56-ecb7f0cf76aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531982bd-a64c-4475-9786-01594a9c8d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65541cee-309a-450f-a884-43ae220629cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a8091-9340-4c70-a12e-9bcbb2a769d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77cc9c5-c4e5-46cb-b798-542a8da78c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "62cf392a-46da-435e-80c5-059d34da3fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load DataFrame and Preprocess\n",
    "# Assume combined_df_stand is already loaded\n",
    "entities = list(set(combined_df_stand['Subject']).union(set(combined_df_stand['Object'])))\n",
    "relations = list(set(combined_df_stand['Predicate']))\n",
    "\n",
    "# Create mappings\n",
    "entity_to_id = {entity: idx for idx, entity in enumerate(entities)}\n",
    "relation_to_id = {relation: idx for idx, relation in enumerate(relations)}\n",
    "\n",
    "# Map entities and relations to IDs\n",
    "combined_df_stand['Subject_ID'] = combined_df_stand['Subject'].map(entity_to_id)\n",
    "combined_df_stand['Object_ID'] = combined_df_stand['Object'].map(entity_to_id)\n",
    "combined_df_stand['Predicate_ID'] = combined_df_stand['Predicate'].map(relation_to_id)\n",
    "\n",
    "# Prepare edges and types\n",
    "edge_index = torch.tensor(combined_df_stand[['Subject_ID', 'Object_ID']].values.T, dtype=torch.long)\n",
    "edge_type = torch.tensor(combined_df_stand['Predicate_ID'].values, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0d952e-d220-43b2-b161-fc9fe619b2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf4263-6de4-4864-ade2-031186cb1f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb01ae2b-8387-4602-8728-64b4a2dc3759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c3a97d-6d36-4a8a-8eae-195cfa87843a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4f988f6d-8112-450d-8a1f-fcc3f43cec8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 3: Split Data into Train, Validation, and Test\n",
    "train_df, temp_df = train_test_split(combined_df_stand, test_size=0.3, random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fd590f35-79ba-48ef-bef5-fc127667493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_edges(df):\n",
    "    edge_index = torch.tensor(df[['Subject_ID', 'Object_ID']].values.T, dtype=torch.long)\n",
    "    edge_type = torch.tensor(df['Predicate_ID'].values, dtype=torch.long)\n",
    "    return edge_index, edge_type\n",
    "\n",
    "train_edge_index, train_edge_type = prepare_edges(train_df)\n",
    "val_edge_index, val_edge_type = prepare_edges(val_df)\n",
    "test_edge_index, test_edge_type = prepare_edges(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "341d1588-6dd9-49c3-bc99-0f2ea0e6f4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torch-geometric torch-scatter torch-sparse torch-cluster pyg-lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "402cb55c-a8c9-49a5-82ad-fd28eff42fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch==2.5.1+cpu torchvision==0.15.2+cpu -f https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "eadc9f46-d48e-4b84-a438-32f98acb868e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Geometric version: 2.6.1\n",
      "Torch version: 2.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import Node2Vec\n",
    "\n",
    "print(\"PyTorch Geometric version:\", torch_geometric.__version__)\n",
    "print(\"Torch version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4faae9ad-d496-49fd-8591-6d20c88f8e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Geometric version: 2.6.1\n",
      "Torch version: 2.5.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.nn import Node2Vec\n",
    "\n",
    "print(\"PyTorch Geometric version:\", torch_geometric.__version__)\n",
    "print(\"Torch version:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "32960c4c-c6ca-4110-8921-4da71bc9a0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pyg_lib\n",
      "Version: 0.4.0+pt25\n",
      "Summary: Low-Level Graph Neural Network Operators for PyG\n",
      "Home-page: https://github.com/pyg-team/pyg-lib\n",
      "Author: PyG Team\n",
      "Author-email: team@pyg.org\n",
      "License: \n",
      "Location: /opt/homebrew/Cellar/jupyterlab/4.3.1_1/libexec/lib/python3.12/site-packages\n",
      "Requires: \n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show pyg-lib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "23043e36-c272-429b-96e5-2444fc09c2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch_cluster\n",
      "Version: 1.6.3\n",
      "Summary: PyTorch Extension Library of Optimized Graph Cluster Algorithms\n",
      "Home-page: https://github.com/rusty1s/pytorch_cluster\n",
      "Author: Matthias Fey\n",
      "Author-email: matthias.fey@tu-dortmund.de\n",
      "License: \n",
      "Location: /opt/homebrew/Cellar/jupyterlab/4.3.1_1/libexec/lib/python3.12/site-packages\n",
      "Requires: scipy\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show torch-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0e843b1d-ae2b-4d67-87ab-aa2e0fef6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Initialize Node Features Using Node2Vec\n",
    "num_entities = len(entity_to_id)\n",
    "node2vec = Node2Vec(edge_index, embedding_dim=128, walk_length=10, context_size=5, walks_per_node=5)\n",
    "node2vec.train()\n",
    "node_features = node2vec.embedding.weight.data\n",
    "node_features = (node_features - node_features.mean(dim=0)) / (node_features.std(dim=0) + 1e-6)\n",
    "node_features = node_features / torch.max(torch.abs(node_features))  # Normalize to [-1, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "37b44b89-fdfd-4f19-93e8-93b5f7d33de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define R-GCN Model with Relation Embeddings and MLP Scoring\n",
    "class RGCNModel(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_relations):\n",
    "        super(RGCNModel, self).__init__()\n",
    "        self.conv1 = RGCNConv(input_dim, hidden_dim, num_relations=num_relations)\n",
    "        self.conv2 = RGCNConv(hidden_dim, output_dim, num_relations=num_relations)\n",
    "        self.scoring = torch.nn.Linear(2 * output_dim, 1)  # Scoring via MLP\n",
    "\n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        x = self.conv1(x, edge_index, edge_type)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return x\n",
    "\n",
    "    def predict(self, src, dst):\n",
    "        return self.scoring(torch.cat([src, dst], dim=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6536859b-33ee-4430-a60f-9cb011dc9694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Compute ranking metrics\n",
    "def compute_ranking_metrics(embeddings, pos_edge_index):\n",
    "    ranks = []\n",
    "    hits_at_1, hits_at_3, hits_at_10 = 0, 0, 0\n",
    "\n",
    "    for i in range(pos_edge_index.size(1)):\n",
    "        src, dst = pos_edge_index[0, i], pos_edge_index[1, i]\n",
    "\n",
    "        # Compute similarity scores for all nodes with respect to the source node\n",
    "        scores = torch.matmul(embeddings[src], embeddings.t())\n",
    "        sorted_indices = torch.argsort(scores, descending=True)\n",
    "\n",
    "        # Find the rank of the positive target node\n",
    "        rank = (sorted_indices == dst).nonzero(as_tuple=True)[0].item() + 1\n",
    "        ranks.append(rank)\n",
    "\n",
    "        # Update Hits@K counts\n",
    "        if rank <= 1: hits_at_1 += 1\n",
    "        if rank <= 3: hits_at_3 += 1\n",
    "        if rank <= 10: hits_at_10 += 1\n",
    "\n",
    "    # Compute Mean Rank and MRR\n",
    "    mean_rank = np.mean(ranks)\n",
    "    mrr = np.mean([1.0 / rank for rank in ranks])\n",
    "\n",
    "    # Normalize Hits@K\n",
    "    total_edges = len(ranks)\n",
    "    hits_at_1 /= total_edges\n",
    "    hits_at_3 /= total_edges\n",
    "    hits_at_10 /= total_edges\n",
    "\n",
    "    return mean_rank, mrr, hits_at_1, hits_at_3, hits_at_10\n",
    "\n",
    "def compute_detailed_ranking_metrics(embeddings, pos_edge_index):\n",
    "    ranks = {\"overall\": [], \"head\": [], \"tail\": []}\n",
    "    hits_at_k = {\"overall\": [0, 0, 0], \"head\": [0, 0, 0], \"tail\": [0, 0, 0]}\n",
    "\n",
    "    for i in range(pos_edge_index.size(1)):\n",
    "        src, dst = pos_edge_index[0, i], pos_edge_index[1, i]\n",
    "\n",
    "        # Compute similarity scores for predicting tail\n",
    "        tail_scores = torch.matmul(embeddings[src], embeddings.t())\n",
    "        sorted_tail_indices = torch.argsort(tail_scores, descending=True)\n",
    "        tail_rank = (sorted_tail_indices == dst).nonzero(as_tuple=True)[0].item() + 1\n",
    "        ranks[\"overall\"].append(tail_rank)\n",
    "        ranks[\"tail\"].append(tail_rank)\n",
    "\n",
    "        # Compute similarity scores for predicting head\n",
    "        head_scores = torch.matmul(embeddings[dst], embeddings.t())\n",
    "        sorted_head_indices = torch.argsort(head_scores, descending=True)\n",
    "        head_rank = (sorted_head_indices == src).nonzero(as_tuple=True)[0].item() + 1\n",
    "        ranks[\"overall\"].append(head_rank)\n",
    "        ranks[\"head\"].append(head_rank)\n",
    "\n",
    "    for key in ranks.keys():\n",
    "        total_ranks = len(ranks[key])\n",
    "        hits_at_k[key][0] = sum(1 for rank in ranks[key] if rank <= 1) / total_ranks\n",
    "        hits_at_k[key][1] = sum(1 for rank in ranks[key] if rank <= 3) / total_ranks\n",
    "        hits_at_k[key][2] = sum(1 for rank in ranks[key] if rank <= 10) / total_ranks\n",
    "        ranks[key] = {\n",
    "            \"mean_rank\": np.mean(ranks[key]),\n",
    "            \"mrr\": np.mean([1.0 / rank for rank in ranks[key]]),\n",
    "            \"hits_at_1\": hits_at_k[key][0],\n",
    "            \"hits_at_3\": hits_at_k[key][1],\n",
    "            \"hits_at_10\": hits_at_k[key][2],\n",
    "        }\n",
    "\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4a0350cd-5ef0-4863-a715-905999a0b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_negative_sampling(edge_index, num_nodes, num_neg_samples):\n",
    "    return negative_sampling(\n",
    "        edge_index=edge_index,\n",
    "        num_nodes=num_nodes,\n",
    "        num_neg_samples=num_neg_samples,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c8e57d3a-d62b-4bd6-ab8e-8c7072a2dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function for training\n",
    "def compute_loss(embeddings, edge_index, edge_type):\n",
    "    # Using binary cross-entropy loss with negative sampling\n",
    "    negative_edge_index = safe_negative_sampling(\n",
    "        edge_index=edge_index,\n",
    "        num_nodes=embeddings.size(0),\n",
    "        num_neg_samples=edge_index.size(1),\n",
    "    )\n",
    "    positive_scores = torch.sum(embeddings[edge_index[0]] * embeddings[edge_index[1]], dim=1)\n",
    "    negative_scores = torch.sum(embeddings[negative_edge_index[0]] * embeddings[negative_edge_index[1]], dim=1)\n",
    "\n",
    "     # Debug scores\n",
    "    print(\"Positive Scores Stats:\", positive_scores.min().item(), positive_scores.max().item())\n",
    "    print(\"Negative Scores Stats:\", negative_scores.min().item(), negative_scores.max().item())\n",
    "\n",
    "    loss = -torch.log(torch.sigmoid(positive_scores)).mean() - torch.log(torch.sigmoid(-negative_scores)).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5d713f7a-c870-4086-bcea-586d03059892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Train the RGCN Model\n",
    "model = RGCNModel(input_dim=128, hidden_dim=64, output_dim=128, num_relations=len(relation_to_id))\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "04c1e0f7-1fa9-4203-932c-7128d983b411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Features Stats: -1.0 0.9520599246025085\n",
      "Edge Index Shape: torch.Size([2, 239460])\n",
      "Edge Type Shape: torch.Size([239460])\n"
     ]
    }
   ],
   "source": [
    "# Check node features\n",
    "assert not torch.isnan(node_features).any(), \"Node features contain NaN values!\"\n",
    "assert not torch.isinf(node_features).any(), \"Node features contain Inf values!\"\n",
    "\n",
    "# Check edge index\n",
    "assert not torch.isnan(edge_index).any(), \"Edge index contains NaN values!\"\n",
    "assert not torch.isinf(edge_index).any(), \"Edge index contains Inf values!\"\n",
    "\n",
    "# Check edge type\n",
    "assert not torch.isnan(edge_type).any(), \"Edge type contains NaN values!\"\n",
    "assert not torch.isinf(edge_type).any(), \"Edge type contains Inf values!\"\n",
    "\n",
    "# Print statistics for debugging\n",
    "print(\"Node Features Stats:\", node_features.min().item(), node_features.max().item())\n",
    "print(\"Edge Index Shape:\", edge_index.shape)\n",
    "print(\"Edge Type Shape:\", edge_type.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a9d72fe3-b88c-4e34-9d64-0eb25ab7d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not torch.isinf(node_features).any(), \"Node features contain Inf values!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4b5810a5-8663-49aa-994c-19687af7a766",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not torch.isnan(edge_index).any(), \"Edge index contains NaN values!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "42a27de8-7435-4fd3-8452-22c370674883",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not torch.isinf(edge_index).any(), \"Edge index contains Inf values!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e3bdf422-4003-4e8a-8cfd-9aab1171ad41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Scores Stats: -1.4832713603973389 7.991677284240723\n",
      "Negative Scores Stats: -1.453662633895874 12.365680694580078\n",
      "Epoch 1/50, Loss: 2.6425, Val MRR: 0.0041\n",
      "Positive Scores Stats: -1.508592963218689 7.899600982666016\n",
      "Negative Scores Stats: -1.154632568359375 12.025553703308105\n",
      "Epoch 2/50, Loss: 2.5929, Val MRR: 0.0041\n",
      "Positive Scores Stats: -1.5330815315246582 7.810639381408691\n",
      "Negative Scores Stats: -1.411097526550293 11.835808753967285\n",
      "Epoch 3/50, Loss: 2.5374, Val MRR: 0.0040\n",
      "Positive Scores Stats: -1.5565295219421387 7.7225022315979\n",
      "Negative Scores Stats: -1.4021825790405273 12.959908485412598\n",
      "Epoch 4/50, Loss: 2.4920, Val MRR: 0.0040\n",
      "Positive Scores Stats: -1.57887864112854 7.635150909423828\n",
      "Negative Scores Stats: -1.6067343950271606 13.703432083129883\n",
      "Epoch 5/50, Loss: 2.4406, Val MRR: 0.0040\n",
      "Positive Scores Stats: -1.6003221273422241 7.549386024475098\n",
      "Negative Scores Stats: -1.3479890823364258 12.467480659484863\n",
      "Epoch 6/50, Loss: 2.3963, Val MRR: 0.0039\n",
      "Positive Scores Stats: -1.6208137273788452 7.4651570320129395\n",
      "Negative Scores Stats: -1.6202950477600098 12.971546173095703\n",
      "Epoch 7/50, Loss: 2.3545, Val MRR: 0.0039\n",
      "Positive Scores Stats: -1.6405649185180664 7.382015705108643\n",
      "Negative Scores Stats: -1.3904504776000977 12.741880416870117\n",
      "Epoch 8/50, Loss: 2.3110, Val MRR: 0.0039\n",
      "Positive Scores Stats: -1.6596553325653076 7.3003153800964355\n",
      "Negative Scores Stats: -1.3573815822601318 11.481311798095703\n",
      "Epoch 9/50, Loss: 2.2718, Val MRR: 0.0039\n",
      "Positive Scores Stats: -1.6781895160675049 7.220088481903076\n",
      "Negative Scores Stats: -1.4941060543060303 11.82518196105957\n",
      "Epoch 10/50, Loss: 2.2318, Val MRR: 0.0038\n",
      "Positive Scores Stats: -1.696196436882019 7.1416707038879395\n",
      "Negative Scores Stats: -1.498093843460083 10.534231185913086\n",
      "Epoch 11/50, Loss: 2.1909, Val MRR: 0.0038\n",
      "Positive Scores Stats: -1.7137770652770996 7.0645952224731445\n",
      "Negative Scores Stats: -1.956102728843689 10.833818435668945\n",
      "Epoch 12/50, Loss: 2.1549, Val MRR: 0.0038\n",
      "Positive Scores Stats: -1.730904459953308 6.988979816436768\n",
      "Negative Scores Stats: -1.9948593378067017 10.856675148010254\n",
      "Epoch 13/50, Loss: 2.1227, Val MRR: 0.0037\n",
      "Positive Scores Stats: -1.7476178407669067 6.914882659912109\n",
      "Negative Scores Stats: -2.1253645420074463 11.684172630310059\n",
      "Epoch 14/50, Loss: 2.0903, Val MRR: 0.0037\n",
      "Positive Scores Stats: -1.7638616561889648 6.841778755187988\n",
      "Negative Scores Stats: -1.789634346961975 8.810054779052734\n",
      "Epoch 15/50, Loss: 2.0573, Val MRR: 0.0037\n",
      "Positive Scores Stats: -1.779723882675171 6.770097255706787\n",
      "Negative Scores Stats: -1.5701329708099365 10.995786666870117\n",
      "Epoch 16/50, Loss: 2.0267, Val MRR: 0.0037\n",
      "Positive Scores Stats: -1.7951064109802246 6.700022220611572\n",
      "Negative Scores Stats: -1.6687157154083252 9.973441123962402\n",
      "Epoch 17/50, Loss: 1.9939, Val MRR: 0.0036\n",
      "Positive Scores Stats: -1.810036301612854 6.6315836906433105\n",
      "Negative Scores Stats: -1.802255630493164 10.336584091186523\n",
      "Epoch 18/50, Loss: 1.9648, Val MRR: 0.0036\n",
      "Positive Scores Stats: -1.8244397640228271 6.5645365715026855\n",
      "Negative Scores Stats: -2.0257039070129395 10.566994667053223\n",
      "Epoch 19/50, Loss: 1.9396, Val MRR: 0.0036\n",
      "Positive Scores Stats: -1.8383598327636719 6.49892520904541\n",
      "Negative Scores Stats: -1.833451271057129 10.396953582763672\n",
      "Epoch 20/50, Loss: 1.9149, Val MRR: 0.0036\n",
      "Positive Scores Stats: -1.851721167564392 6.434695720672607\n",
      "Negative Scores Stats: -1.7455614805221558 9.385408401489258\n",
      "Epoch 21/50, Loss: 1.8861, Val MRR: 0.0036\n",
      "Positive Scores Stats: -1.864498496055603 6.371963024139404\n",
      "Negative Scores Stats: -2.260049819946289 9.714067459106445\n",
      "Epoch 22/50, Loss: 1.8622, Val MRR: 0.0035\n",
      "Positive Scores Stats: -1.8766164779663086 6.311067581176758\n",
      "Negative Scores Stats: -2.163418769836426 9.838812828063965\n",
      "Epoch 23/50, Loss: 1.8378, Val MRR: 0.0035\n",
      "Positive Scores Stats: -1.8880831003189087 6.251875877380371\n",
      "Negative Scores Stats: -2.1516144275665283 9.910331726074219\n",
      "Epoch 24/50, Loss: 1.8173, Val MRR: 0.0035\n",
      "Positive Scores Stats: -1.8989561796188354 6.194248199462891\n",
      "Negative Scores Stats: -1.6398048400878906 9.915332794189453\n",
      "Epoch 25/50, Loss: 1.7962, Val MRR: 0.0035\n",
      "Positive Scores Stats: -1.9091683626174927 6.138254165649414\n",
      "Negative Scores Stats: -2.194167137145996 9.041036605834961\n",
      "Epoch 26/50, Loss: 1.7743, Val MRR: 0.0035\n",
      "Positive Scores Stats: -1.9187664985656738 6.082881450653076\n",
      "Negative Scores Stats: -1.7022016048431396 8.696141242980957\n",
      "Epoch 27/50, Loss: 1.7562, Val MRR: 0.0035\n",
      "Positive Scores Stats: -1.9277011156082153 6.02888298034668\n",
      "Negative Scores Stats: -2.3714663982391357 9.232854843139648\n",
      "Epoch 28/50, Loss: 1.7346, Val MRR: 0.0035\n",
      "Positive Scores Stats: -1.9360778331756592 5.976709365844727\n",
      "Negative Scores Stats: -1.9002426862716675 9.686626434326172\n",
      "Epoch 29/50, Loss: 1.7189, Val MRR: 0.0035\n",
      "Positive Scores Stats: -1.9439548254013062 5.925772190093994\n",
      "Negative Scores Stats: -2.4011871814727783 9.575429916381836\n",
      "Epoch 30/50, Loss: 1.6981, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9513521194458008 5.876755714416504\n",
      "Negative Scores Stats: -1.9513521194458008 9.587810516357422\n",
      "Epoch 31/50, Loss: 1.6829, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9582030773162842 5.829281806945801\n",
      "Negative Scores Stats: -2.2645957469940186 9.488425254821777\n",
      "Epoch 32/50, Loss: 1.6699, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9643608331680298 5.783453941345215\n",
      "Negative Scores Stats: -1.9643608331680298 9.39281940460205\n",
      "Epoch 33/50, Loss: 1.6524, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.969742774963379 5.7388176918029785\n",
      "Negative Scores Stats: -1.8302488327026367 7.879832744598389\n",
      "Epoch 34/50, Loss: 1.6381, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9744751453399658 5.695773601531982\n",
      "Negative Scores Stats: -1.8866628408432007 9.018014907836914\n",
      "Epoch 35/50, Loss: 1.6245, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9785871505737305 5.654089450836182\n",
      "Negative Scores Stats: -1.8303860425949097 8.216287612915039\n",
      "Epoch 36/50, Loss: 1.6084, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9821785688400269 5.61397123336792\n",
      "Negative Scores Stats: -2.0360045433044434 7.994393348693848\n",
      "Epoch 37/50, Loss: 1.5956, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9853047132492065 5.574947834014893\n",
      "Negative Scores Stats: -2.290628433227539 8.496776580810547\n",
      "Epoch 38/50, Loss: 1.5827, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9879194498062134 5.537216663360596\n",
      "Negative Scores Stats: -2.01637864112854 7.930224418640137\n",
      "Epoch 39/50, Loss: 1.5701, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9899086952209473 5.500431537628174\n",
      "Negative Scores Stats: -2.380617380142212 8.604395866394043\n",
      "Epoch 40/50, Loss: 1.5596, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9914908409118652 5.464459419250488\n",
      "Negative Scores Stats: -1.9711308479309082 7.623345375061035\n",
      "Epoch 41/50, Loss: 1.5460, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9926955699920654 5.429617404937744\n",
      "Negative Scores Stats: -2.0528335571289062 8.680839538574219\n",
      "Epoch 42/50, Loss: 1.5377, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9934759140014648 5.39607048034668\n",
      "Negative Scores Stats: -1.872886061668396 7.803770542144775\n",
      "Epoch 43/50, Loss: 1.5255, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9937907457351685 5.363903999328613\n",
      "Negative Scores Stats: -2.083843946456909 7.816740989685059\n",
      "Epoch 44/50, Loss: 1.5166, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9937556982040405 5.333071708679199\n",
      "Negative Scores Stats: -3.4587063789367676 7.9090895652771\n",
      "Epoch 45/50, Loss: 1.5074, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.993453025817871 5.303411483764648\n",
      "Negative Scores Stats: -2.1613733768463135 6.554656028747559\n",
      "Epoch 46/50, Loss: 1.4980, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9927341938018799 5.2750630378723145\n",
      "Negative Scores Stats: -2.186232566833496 8.375066757202148\n",
      "Epoch 47/50, Loss: 1.4884, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9917092323303223 5.247671604156494\n",
      "Negative Scores Stats: -2.0007946491241455 8.32208251953125\n",
      "Epoch 48/50, Loss: 1.4810, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9903149604797363 5.221663951873779\n",
      "Negative Scores Stats: -2.007387399673462 6.955352306365967\n",
      "Epoch 49/50, Loss: 1.4716, Val MRR: 0.0034\n",
      "Positive Scores Stats: -1.9886820316314697 5.197197437286377\n",
      "Negative Scores Stats: -2.0000336170196533 7.596633434295654\n",
      "Epoch 50/50, Loss: 1.4652, Val MRR: 0.0034\n"
     ]
    }
   ],
   "source": [
    "def train(model, optimizer, node_features, train_edge_index, train_edge_type, val_edge_index, val_edge_type, num_epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        embeddings = model(node_features, train_edge_index, train_edge_type)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = compute_loss(embeddings, train_edge_index, train_edge_type)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Validation metrics\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_embeddings = model(node_features, val_edge_index, val_edge_type)\n",
    "            mean_rank, mrr, hits_at_1, hits_at_3, hits_at_10 = compute_ranking_metrics(val_embeddings, val_edge_index)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}, Val MRR: {mrr:.4f}\")\n",
    "\n",
    "train(model, optimizer, node_features, train_edge_index, train_edge_type, val_edge_index, val_edge_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bd0ae7-7167-471d-bf8a-5a137908ec78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "eed1cb7b-4505-4429-b6f0-75cd33e119ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "Mean Rank (MR): 1005.6535\n",
      "Mean Reciprocal Rank (MRR): 0.0022\n",
      "Hits@1: 0.0000\n",
      "Hits@3: 0.0002\n",
      "Hits@10: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate on Validation or Test Set\n",
    "print(\"Validation Metrics:\")\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_embeddings = model(node_features, edge_index, edge_type)\n",
    "    mean_rank, mrr, hits_at_1, hits_at_3, hits_at_10 = compute_ranking_metrics(val_embeddings, edge_index)\n",
    "    ranking_metrics = compute_detailed_ranking_metrics(val_embeddings, edge_index)\n",
    "    print(f\"Mean Rank (MR): {mean_rank:.4f}\")\n",
    "    print(f\"Mean Reciprocal Rank (MRR): {mrr:.4f}\")\n",
    "    print(f\"Hits@1: {hits_at_1:.4f}\")\n",
    "    print(f\"Hits@3: {hits_at_3:.4f}\")\n",
    "    print(f\"Hits@10: {hits_at_10:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "09581cf1-3139-49ed-9fb7-9eda36de57b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Metric     Overall  Head Prediction  Tail Prediction\n",
      "0                   Mean Rank  950.816126       895.978740      1005.653512\n",
      "1  Mean Reciprocal Rank (MRR)    0.003170         0.004129         0.002211\n",
      "2                      Hits@1    0.000025         0.000025         0.000025\n",
      "3                      Hits@3    0.000651         0.001140         0.000163\n",
      "4                     Hits@10    0.003339         0.005725         0.000952\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame for detailed metrics\n",
    "performance_data_RGCN = {\n",
    "    \"Metric\": [\"Mean Rank\", \"Mean Reciprocal Rank (MRR)\", \"Hits@1\", \"Hits@3\", \"Hits@10\"],\n",
    "    \"Overall\": [\n",
    "        ranking_metrics[\"overall\"][\"mean_rank\"],\n",
    "        ranking_metrics[\"overall\"][\"mrr\"],\n",
    "        ranking_metrics[\"overall\"][\"hits_at_1\"],\n",
    "        ranking_metrics[\"overall\"][\"hits_at_3\"],\n",
    "        ranking_metrics[\"overall\"][\"hits_at_10\"],\n",
    "    ],\n",
    "    \"Head Prediction\": [\n",
    "        ranking_metrics[\"head\"][\"mean_rank\"],\n",
    "        ranking_metrics[\"head\"][\"mrr\"],\n",
    "        ranking_metrics[\"head\"][\"hits_at_1\"],\n",
    "        ranking_metrics[\"head\"][\"hits_at_3\"],\n",
    "        ranking_metrics[\"head\"][\"hits_at_10\"],\n",
    "    ],\n",
    "    \"Tail Prediction\": [\n",
    "        ranking_metrics[\"tail\"][\"mean_rank\"],\n",
    "        ranking_metrics[\"tail\"][\"mrr\"],\n",
    "        ranking_metrics[\"tail\"][\"hits_at_1\"],\n",
    "        ranking_metrics[\"tail\"][\"hits_at_3\"],\n",
    "        ranking_metrics[\"tail\"][\"hits_at_10\"],\n",
    "    ],\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(performance_data_RGCN)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9f644c74-2dec-4fd8-bd63-a228baa21711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Metrics:\n",
      "Mean Rank (MR): 1005.6535\n",
      "Mean Reciprocal Rank (MRR): 0.0022\n",
      "Hits@1: 0.0000\n",
      "Hits@3: 0.0002\n",
      "Hits@10: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Testing (Same as validation)\n",
    "print(\"Testing Metrics:\")\n",
    "with torch.no_grad():\n",
    "    test_embeddings = model(node_features, edge_index, edge_type)\n",
    "    mean_rank, mrr, hits_at_1, hits_at_3, hits_at_10 = compute_ranking_metrics(test_embeddings, edge_index)\n",
    "    ranking_metrics = compute_detailed_ranking_metrics(test_embeddings, edge_index)\n",
    "    print(f\"Mean Rank (MR): {mean_rank:.4f}\")\n",
    "    print(f\"Mean Reciprocal Rank (MRR): {mrr:.4f}\")\n",
    "    print(f\"Hits@1: {hits_at_1:.4f}\")\n",
    "    print(f\"Hits@3: {hits_at_3:.4f}\")\n",
    "    print(f\"Hits@10: {hits_at_10:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4119e0-481b-4398-b888-04605446f9e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d30692d-bc60-42b2-83d1-06b31b33959e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ccc955-c20b-4f87-bcdb-9535331fb6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ad508-ae37-4f2c-b329-bcdf55c6d3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f358ae-f31f-4647-8ce8-4bf94b1ab5ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e873ca8-27d9-41de-8157-e365495b6d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "646e361f-0801-4072-9ef1-47a793c78eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Number of Classes': 51573, 'Number of Object Properties': 21, 'Number of Annotation Properties': 79, 'Sample Classes': ['GO_0003674', 'GO_0005575', 'GO_0008150', 'GO_0000001', 'GO_0048308', 'GO_0048311', 'GO_0000002', 'GO_0007005', 'GO_0000003', 'GO_0000004'], 'Sample Object Properties': ['BFO_0000050', 'BFO_0000051', 'BFO_0000066', 'RO_0002091', 'RO_0002092', 'RO_0002093', 'RO_0002211', 'RO_0002212', 'RO_0002213', 'isAssociatedWithPathway'], 'Sample Annotation Properties': ['comment', 'label', 'deprecated', 'description', 'title', 'default-namespace', 'hasOBOFormatVersion', 'hasDbXref', 'hasOBONamespace', 'id']}\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import get_ontology\n",
    "\n",
    "# Load the ontology\n",
    "ontology_path = \"enriched_ppio_ontology_final_54_small.owl\"  # Replace with your local file path\n",
    "ontology = get_ontology(ontology_path).load()\n",
    "\n",
    "# Extract class names\n",
    "class_names = [cls.name for cls in ontology.classes()]\n",
    "\n",
    "# Extract relationships (object properties)\n",
    "object_properties = [prop.name for prop in ontology.object_properties()]\n",
    "\n",
    "# Extract annotation properties (metadata fields)\n",
    "annotation_properties = [prop.name for prop in ontology.annotation_properties()]\n",
    "\n",
    "# Display extracted information\n",
    "ontology_summary = {\n",
    "    \"Number of Classes\": len(class_names),\n",
    "    \"Number of Object Properties\": len(object_properties),\n",
    "    \"Number of Annotation Properties\": len(annotation_properties),\n",
    "    \"Sample Classes\": class_names[:10],  # Show only first 10 classes\n",
    "    \"Sample Object Properties\": object_properties[:10],\n",
    "    \"Sample Annotation Properties\": annotation_properties[:10],\n",
    "}\n",
    "\n",
    "print(ontology_summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffdde32-1096-4e1c-aee1-78cfcd4443e8",
   "metadata": {},
   "source": [
    "## Extract Nodes, Edges, and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b9429-ab97-4966-b40b-aa319176e0a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b8bf1052-fb77-411b-85ac-fe929bf790e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from owlready2 import get_ontology\n",
    "# import pandas as pd\n",
    "# import torch\n",
    "# from torch_geometric.data import Data\n",
    "# from torch_geometric.utils import negative_sampling\n",
    "# from torch_geometric.nn import GCNConv\n",
    "\n",
    "# # Load the ontology\n",
    "# ontology_path = \"enriched_ppio_ontology_final_54_small.owl\"  # Path to your OWL file\n",
    "# ontology = get_ontology(ontology_path).load()\n",
    "\n",
    "# # Define relationships to extract\n",
    "# relations_of_interest = [\"hasSample\", \"hasGeneExpression\", \"isAssociatedWithPathway\", \"isAssociatedWith\"]\n",
    "\n",
    "# # Initialize node and edge storage\n",
    "# nodes = set()\n",
    "# edges = []\n",
    "# metadata = {}\n",
    "\n",
    "# # Extract nodes and edges\n",
    "# for entity in ontology.individuals():\n",
    "#     # Add entity to nodes\n",
    "#     nodes.add(entity.name)\n",
    "    \n",
    "#     # Extract relationships for the entity\n",
    "#     for prop in entity.get_properties():\n",
    "#         for value in prop[entity]:\n",
    "#             if hasattr(value, \"name\"):  # Ensure value is another entity\n",
    "#                 nodes.add(value.name)\n",
    "#                 edges.append((entity.name, prop.python_name, value.name))\n",
    "    \n",
    "#     # Add metadata for specific node types\n",
    "#     if \"Patient\" in [cls.name for cls in entity.is_a]:\n",
    "#         metadata[entity.name] = {\n",
    "#             \"age\": getattr(entity, \"hasAge\", [\"NA\"])[0],\n",
    "#             \"gender\": getattr(entity, \"hasGender\", [\"NA\"])[0],\n",
    "#             \"disease_status\": getattr(entity, \"hasDiseaseStatus\", [\"NA\"])[0],\n",
    "#         }\n",
    "#     elif \"Sample\" in [cls.name for cls in entity.is_a]:\n",
    "#         metadata[entity.name] = {\"num_genes\": len(getattr(entity, \"hasGeneExpression\", []))}\n",
    "\n",
    "# # Convert nodes and edges to DataFrame\n",
    "# edges_df = pd.DataFrame(edges, columns=[\"Source\", \"Relation\", \"Target\"])\n",
    "# nodes_df = pd.DataFrame(list(nodes), columns=[\"Node\"])\n",
    "\n",
    "# # Display extracted data\n",
    "# print(\"### Nodes ###\")\n",
    "# print(nodes_df.head())\n",
    "# print(\"\\n### Edges ###\")\n",
    "# print(edges_df.head())\n",
    "# print(\"\\n### Metadata ###\")\n",
    "# print(pd.DataFrame.from_dict(metadata, orient=\"index\").head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "802d52c1-8802-485f-a42c-efbab220d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from owlready2 import get_ontology\n",
    "import pandas as pd\n",
    "\n",
    "# Load ontology\n",
    "ontology_path = \"enriched_ppio_ontology_final_54_small.owl\"\n",
    "ontology = get_ontology(ontology_path).load()\n",
    "\n",
    "# Relationships of interest\n",
    "relations_of_interest = [\"hasSample\", \"hasGeneExpression\", \"isAssociatedWithPathway\", \"isAssociatedWith\"]\n",
    "\n",
    "# Initialize storage\n",
    "nodes = set()\n",
    "edges = []\n",
    "edge_metadata = {}  # Store expression values\n",
    "metadata = {}\n",
    "\n",
    "# Helper function to safely get attribute values\n",
    "def safe_getattr(entity, attr, default=\"NA\"):\n",
    "    \"\"\"Returns first value if available, otherwise returns default\"\"\"\n",
    "    values = getattr(entity, attr, [])\n",
    "    return values[0].name if values and hasattr(values[0], \"name\") else (values[0] if values else default)\n",
    "\n",
    "# Process individuals in ontology\n",
    "for entity in ontology.individuals():\n",
    "    entity_name = entity.name\n",
    "    nodes.add(entity_name)\n",
    "\n",
    "    # Extract edges\n",
    "    for prop in entity.get_properties():\n",
    "        if prop.python_name in relations_of_interest:\n",
    "            for value in prop[entity]:\n",
    "                if hasattr(value, \"name\"):  \n",
    "                    nodes.add(value.name)\n",
    "                    edges.append((entity_name, prop.python_name, value.name))\n",
    "\n",
    "    # Identify entity class type\n",
    "    entity_classes = [cls.name for cls in entity.is_a]\n",
    "\n",
    "    # Store metadata for Patients\n",
    "    if \"Patient\" in entity_classes:\n",
    "        metadata[entity_name] = {\n",
    "            \"type\": \"Patient\",\n",
    "            \"age\": safe_getattr(entity, \"hasAge\"),\n",
    "            \"gender\": safe_getattr(entity, \"hasGender\"),\n",
    "            \"disease_status\": safe_getattr(entity, \"hasDiseaseStatus\"),\n",
    "            \"group_id\": safe_getattr(entity, \"hasGroupId\"),\n",
    "            \"site_of_infection\": safe_getattr(entity, \"hasSiteOfInfection\"),\n",
    "            \"severity\": safe_getattr(entity, \"hasSeverity\"),\n",
    "        }\n",
    "\n",
    "    # Store metadata for Samples\n",
    "    elif \"Sample\" in entity_classes:\n",
    "        metadata[entity_name] = {\n",
    "            \"type\": \"Sample\",\n",
    "            \"num_genes\": len(getattr(entity, \"hasGeneExpression\", [])),\n",
    "            \"source\": safe_getattr(entity, \"isSourcedFrom\"),\n",
    "            \"tissue\": safe_getattr(entity, \"hasTissue\"),\n",
    "            \"neutrophil_proportion\": safe_getattr(entity, \"hasNeutrophilProportion\"),\n",
    "        }\n",
    "\n",
    "    # Store metadata for Genes\n",
    "    elif \"Gene\" in entity_classes:\n",
    "        metadata[entity_name] = {\n",
    "            \"type\": \"Gene\",\n",
    "            \"entrez_id\": safe_getattr(entity, \"hasEntrezId\"),\n",
    "            \"pathway\": safe_getattr(entity, \"isAssociatedWithPathway\"),\n",
    "        }\n",
    "\n",
    "# Extract annotated edges (Gene-Sample expression values) using get_triples()\n",
    "for subj, pred, obj in ontology.get_triples():\n",
    "    subj_name = subj.name if hasattr(subj, \"name\") else None\n",
    "    pred_name = pred.name if hasattr(pred, \"name\") else None\n",
    "    obj_name = obj.name if hasattr(obj, \"name\") else None\n",
    "\n",
    "    # Check if it's an expression value annotation\n",
    "    if pred_name == \"hasExpressionValue\":\n",
    "        if subj_name and obj_name:\n",
    "            expression_value = float(obj) if isinstance(obj, (int, float)) else \"NA\"\n",
    "            edges.append((subj_name, \"hasGeneExpression\", obj_name))\n",
    "            edge_metadata[(subj_name, obj_name)] = expression_value  \n",
    "\n",
    "# Convert to DataFrames\n",
    "edges_df = pd.DataFrame(edges, columns=[\"Source\", \"Relation\", \"Target\"])\n",
    "nodes_df = pd.DataFrame(list(nodes), columns=[\"Node\"])\n",
    "\n",
    "# Add expression values to edges DataFrame\n",
    "edges_df[\"ExpressionValue\"] = edges_df.apply(lambda row: edge_metadata.get((row[\"Source\"], row[\"Target\"]), \"NA\"), axis=1)\n",
    "\n",
    "# Convert metadata dictionary to DataFrame\n",
    "metadata_df = pd.DataFrame.from_dict(metadata, orient=\"index\")\n",
    "metadata_df.fillna(\"NA\", inplace=True)\n",
    "metadata_df = metadata_df.astype(str)  # Ensure consistent data format\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a919eb1-6d54-479a-85ad-ca7947246387",
   "metadata": {},
   "source": [
    "## Create Node Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fe35692b-bea2-4cd3-a6a8-bd36f12cefd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from owlready2 import get_ontology\n",
    "import pandas as pd\n",
    "\n",
    "# Load ontology\n",
    "ontology_path = \"enriched_ppio_ontology_final_54_small.owl\"\n",
    "ontology = get_ontology(ontology_path).load()\n",
    "\n",
    "# Storage\n",
    "nodes = set()\n",
    "edges = []\n",
    "edge_metadata = {}  # Store expression values\n",
    "metadata = {}\n",
    "\n",
    "# Helper function to safely get attribute values\n",
    "def safe_getattr(entity, attr, default=\"NA\"):\n",
    "    values = getattr(entity, attr, [])\n",
    "    return values[0].name if values and hasattr(values[0], \"name\") else (values[0] if values else default)\n",
    "\n",
    "# Process individuals\n",
    "for entity in ontology.individuals():\n",
    "    entity_name = entity.name\n",
    "    nodes.add(entity_name)\n",
    "\n",
    "    # Extract edges\n",
    "    for prop in entity.get_properties():\n",
    "        for value in prop[entity]:\n",
    "            if hasattr(value, \"name\"):\n",
    "                nodes.add(value.name)\n",
    "                edges.append((entity_name, prop.python_name, value.name))\n",
    "\n",
    "    # Identify entity type and metadata\n",
    "    entity_classes = [cls.name for cls in entity.is_a]\n",
    "    \n",
    "    if \"Patient\" in entity_classes:\n",
    "        metadata[entity_name] = {\n",
    "            \"type\": \"Patient\",\n",
    "            \"age\": safe_getattr(entity, \"hasAge\"),\n",
    "            \"gender\": safe_getattr(entity, \"hasGender\"),\n",
    "            \"disease_status\": safe_getattr(entity, \"hasDiseaseStatus\"),\n",
    "            \"group_id\": safe_getattr(entity, \"hasGroupId\"),\n",
    "            \"site_of_infection\": safe_getattr(entity, \"hasSiteOfInfection\"),\n",
    "            \"severity\": safe_getattr(entity, \"hasSeverity\"),\n",
    "        }\n",
    "    elif \"Sample\" in entity_classes:\n",
    "        metadata[entity_name] = {\n",
    "            \"type\": \"Sample\",\n",
    "            \"num_genes\": len(getattr(entity, \"hasGeneExpression\", [])),\n",
    "            \"tissue\": safe_getattr(entity, \"hasTissue\"),\n",
    "            \"neutrophil_proportion\": safe_getattr(entity, \"hasNeutrophilProportion\"),\n",
    "        }\n",
    "    elif \"Gene\" in entity_classes:\n",
    "        metadata[entity_name] = {\n",
    "            \"type\": \"Gene\",\n",
    "            \"entrez_id\": safe_getattr(entity, \"hasEntrezId\"),\n",
    "            \"pathway\": safe_getattr(entity, \"isAssociatedWithPathway\"),\n",
    "        }\n",
    "\n",
    "# Extract annotated edges with expression values\n",
    "for subj, pred, obj in ontology.get_triples():\n",
    "    if hasattr(pred, \"name\") and pred.name == \"hasExpressionValue\":\n",
    "        source = subj.name if hasattr(subj, \"name\") else None\n",
    "        target = obj.name if hasattr(obj, \"name\") else None\n",
    "        value = getattr(obj, \"value\", None)  # Get numerical expression value\n",
    "        \n",
    "        if source and target and value:\n",
    "            edge_metadata[(source, target)] = float(value) if isinstance(value, (int, float)) else \"NA\"\n",
    "\n",
    "# Convert to DataFrames\n",
    "edges_df = pd.DataFrame(edges, columns=[\"Source\", \"Relation\", \"Target\"])\n",
    "\n",
    "# Assign expression values\n",
    "edges_df[\"ExpressionValue\"] = edges_df.apply(lambda row: edge_metadata.get((row[\"Source\"], row[\"Target\"]), \"NA\"), axis=1)\n",
    "\n",
    "# Convert metadata to DataFrame\n",
    "metadata_df = pd.DataFrame.from_dict(metadata, orient=\"index\").fillna(\"NA\").astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "92d8c5d7-ba0f-4ae2-a20d-ee5ee2f4813e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Nodes ###\n",
      "              Node\n",
      "0       Gene_54458\n",
      "1      Gene_728518\n",
      "2       Gene_64432\n",
      "3      Gene_170960\n",
      "4      Gene_115548\n",
      "5        Gene_5504\n",
      "6       GO_0016605\n",
      "7     Patient_S_46\n",
      "8  Protein_PRKAR1A\n",
      "9   Protein_GOLGA3\n",
      "\n",
      "### Edges ###\n",
      "              Source           Relation             Target ExpressionValue\n",
      "0       Patient_HC_1           isPartOf           GSE54514              NA\n",
      "1       Patient_HC_1          hasSample  Sample_GSM1317896              NA\n",
      "2       Patient_HC_1          hasSample  Sample_GSM1318041              NA\n",
      "3  Sample_GSM1317896  hasGeneExpression         Gene_60496              NA\n",
      "4  Sample_GSM1317896  hasGeneExpression            Gene_18              NA\n",
      "5  Sample_GSM1317896  hasGeneExpression         Gene_10347              NA\n",
      "6  Sample_GSM1317896  hasGeneExpression           Gene_215              NA\n",
      "7  Sample_GSM1317896  hasGeneExpression            Gene_23              NA\n",
      "8  Sample_GSM1317896  hasGeneExpression            Gene_26              NA\n",
      "9  Sample_GSM1317896  hasGeneExpression         Gene_27034              NA\n",
      "\n",
      "### Metadata ###\n",
      "                 type age gender disease_status group_id site_of_infection  \\\n",
      "Patient_HC_1  Patient  42      F        healthy     HC_1                NA   \n",
      "Gene_60496       Gene  NA     NA             NA       NA                NA   \n",
      "Gene_18          Gene  NA     NA             NA       NA                NA   \n",
      "Gene_10347       Gene  NA     NA             NA       NA                NA   \n",
      "Gene_215         Gene  NA     NA             NA       NA                NA   \n",
      "Gene_23          Gene  NA     NA             NA       NA                NA   \n",
      "Gene_26          Gene  NA     NA             NA       NA                NA   \n",
      "Gene_27034       Gene  NA     NA             NA       NA                NA   \n",
      "Gene_37          Gene  NA     NA             NA       NA                NA   \n",
      "Gene_91452       Gene  NA     NA             NA       NA                NA   \n",
      "\n",
      "             severity entrez_id          pathway  \n",
      "Patient_HC_1       NA        NA               NA  \n",
      "Gene_60496         NA        NA  Pathway_0000000  \n",
      "Gene_18            NA        NA  Pathway_0000000  \n",
      "Gene_10347         NA        NA  Pathway_0000000  \n",
      "Gene_215           NA        NA  Pathway_0000000  \n",
      "Gene_23            NA        NA  Pathway_0000000  \n",
      "Gene_26            NA        NA  Pathway_0000000  \n",
      "Gene_27034         NA        NA  Pathway_0000000  \n",
      "Gene_37            NA        NA  Pathway_0000000  \n",
      "Gene_91452         NA        NA  Pathway_0000000  \n"
     ]
    }
   ],
   "source": [
    "# Display extracted data\n",
    "print(\"### Nodes ###\")\n",
    "print(nodes_df.head(10))\n",
    "print(\"\\n### Edges ###\")\n",
    "print(edges_df.head(10))\n",
    "print(\"\\n### Metadata ###\")\n",
    "print(metadata_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331fdb55-2411-4108-8382-e24940954aff",
   "metadata": {},
   "source": [
    "## Define GCN for Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "8f3e9942-6b4a-46d0-874b-4edd03ac392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GCN model\n",
    "class GCNLinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCNLinkPredictor, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Initialize model, optimizer, and loss function\n",
    "input_dim = node_features_tensor.size(1)\n",
    "model = GCNLinkPredictor(input_dim=input_dim, hidden_dim=64, output_dim=32)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a998fed2-d879-4534-bdcd-293b4ef8c5a7",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "10fcbbc4-68f2-4b58-8d45-455d67977dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2075.3838\n",
      "Epoch 2, Loss: 868.5792\n",
      "Epoch 3, Loss: 300.2424\n",
      "Epoch 4, Loss: 156.5396\n",
      "Epoch 5, Loss: 192.4181\n",
      "Epoch 6, Loss: 235.3768\n",
      "Epoch 7, Loss: 230.8152\n",
      "Epoch 8, Loss: 191.8416\n",
      "Epoch 9, Loss: 152.7773\n",
      "Epoch 10, Loss: 124.4660\n",
      "Epoch 11, Loss: 106.1344\n",
      "Epoch 12, Loss: 92.8360\n",
      "Epoch 13, Loss: 82.2695\n",
      "Epoch 14, Loss: 73.5834\n",
      "Epoch 15, Loss: 64.2566\n",
      "Epoch 16, Loss: 53.9726\n",
      "Epoch 17, Loss: 43.8109\n",
      "Epoch 18, Loss: 34.7930\n",
      "Epoch 19, Loss: 27.3244\n",
      "Epoch 20, Loss: 22.1782\n",
      "Epoch 21, Loss: 19.0790\n",
      "Epoch 22, Loss: 17.6460\n",
      "Epoch 23, Loss: 17.7682\n",
      "Epoch 24, Loss: 18.2199\n",
      "Epoch 25, Loss: 18.7809\n",
      "Epoch 26, Loss: 18.8495\n",
      "Epoch 27, Loss: 18.5286\n",
      "Epoch 28, Loss: 17.1012\n",
      "Epoch 29, Loss: 15.3378\n",
      "Epoch 30, Loss: 13.1323\n",
      "Epoch 31, Loss: 10.8185\n",
      "Epoch 32, Loss: 8.6821\n",
      "Epoch 33, Loss: 6.8919\n",
      "Epoch 34, Loss: 5.5021\n",
      "Epoch 35, Loss: 4.4623\n",
      "Epoch 36, Loss: 3.8033\n",
      "Epoch 37, Loss: 3.4712\n",
      "Epoch 38, Loss: 3.3428\n",
      "Epoch 39, Loss: 3.3545\n",
      "Epoch 40, Loss: 3.4015\n",
      "Epoch 41, Loss: 3.4280\n",
      "Epoch 42, Loss: 3.4166\n",
      "Epoch 43, Loss: 3.3229\n",
      "Epoch 44, Loss: 3.1483\n",
      "Epoch 45, Loss: 2.9383\n",
      "Epoch 46, Loss: 2.6811\n",
      "Epoch 47, Loss: 2.3880\n",
      "Epoch 48, Loss: 2.0970\n",
      "Epoch 49, Loss: 1.8291\n",
      "Epoch 50, Loss: 1.5703\n",
      "Epoch 51, Loss: 1.3655\n",
      "Epoch 52, Loss: 1.2135\n",
      "Epoch 53, Loss: 1.1132\n",
      "Epoch 54, Loss: 1.0551\n",
      "Epoch 55, Loss: 1.0429\n",
      "Epoch 56, Loss: 1.0459\n",
      "Epoch 57, Loss: 1.0476\n",
      "Epoch 58, Loss: 1.0468\n",
      "Epoch 59, Loss: 1.0411\n",
      "Epoch 60, Loss: 1.0220\n",
      "Epoch 61, Loss: 0.9975\n",
      "Epoch 62, Loss: 0.9653\n",
      "Epoch 63, Loss: 0.9347\n",
      "Epoch 64, Loss: 0.9041\n",
      "Epoch 65, Loss: 0.8788\n",
      "Epoch 66, Loss: 0.8532\n",
      "Epoch 67, Loss: 0.8292\n",
      "Epoch 68, Loss: 0.8090\n",
      "Epoch 69, Loss: 0.7916\n",
      "Epoch 70, Loss: 0.7748\n",
      "Epoch 71, Loss: 0.7594\n",
      "Epoch 72, Loss: 0.7453\n",
      "Epoch 73, Loss: 0.7320\n",
      "Epoch 74, Loss: 0.7215\n",
      "Epoch 75, Loss: 0.7126\n",
      "Epoch 76, Loss: 0.7070\n",
      "Epoch 77, Loss: 0.7039\n",
      "Epoch 78, Loss: 0.7025\n",
      "Epoch 79, Loss: 0.7011\n",
      "Epoch 80, Loss: 0.7012\n",
      "Epoch 81, Loss: 0.7015\n",
      "Epoch 82, Loss: 0.7026\n",
      "Epoch 83, Loss: 0.7026\n",
      "Epoch 84, Loss: 0.7029\n",
      "Epoch 85, Loss: 0.7021\n",
      "Epoch 86, Loss: 0.7005\n",
      "Epoch 87, Loss: 0.6984\n",
      "Epoch 88, Loss: 0.6961\n",
      "Epoch 89, Loss: 0.6935\n",
      "Epoch 90, Loss: 0.6910\n",
      "Epoch 91, Loss: 0.6881\n",
      "Epoch 92, Loss: 0.6866\n",
      "Epoch 93, Loss: 0.6845\n",
      "Epoch 94, Loss: 0.6826\n",
      "Epoch 95, Loss: 0.6808\n",
      "Epoch 96, Loss: 0.6797\n",
      "Epoch 97, Loss: 0.6785\n",
      "Epoch 98, Loss: 0.6778\n",
      "Epoch 99, Loss: 0.6775\n",
      "Epoch 100, Loss: 0.6773\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split edges into train and test sets\n",
    "edges_train, edges_test = train_test_split(edge_index.t().tolist(), test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to tensors\n",
    "edges_train = torch.tensor(edges_train, dtype=torch.long).t()\n",
    "edges_test = torch.tensor(edges_test, dtype=torch.long).t()\n",
    "\n",
    "# Generate negative samples\n",
    "def generate_negative_samples(edge_index, num_nodes, num_neg_samples):\n",
    "    neg_samples = negative_sampling(\n",
    "        edge_index=edge_index, num_nodes=num_nodes, num_neg_samples=num_neg_samples\n",
    "    )\n",
    "    return neg_samples\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    embeddings = model(node_features_tensor, edges_train)\n",
    "    \n",
    "    # Positive edges\n",
    "    pos_edge_scores = (embeddings[edges_train[0]] * embeddings[edges_train[1]]).sum(dim=1)\n",
    "    \n",
    "    # Negative edges\n",
    "    neg_edges = generate_negative_samples(edges_train, len(nodes), edges_train.size(1))\n",
    "    neg_edge_scores = (embeddings[neg_edges[0]] * embeddings[neg_edges[1]]).sum(dim=1)\n",
    "    \n",
    "    # Compute loss\n",
    "    pos_labels = torch.ones(pos_edge_scores.size(0))\n",
    "    neg_labels = torch.zeros(neg_edge_scores.size(0))\n",
    "    loss = loss_fn(torch.cat([pos_edge_scores, neg_edge_scores]), torch.cat([pos_labels, neg_labels]))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7183880d-144c-44da-aea1-d2b60a3a5413",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "19f149e3-ec80-4928-b6c6-78ac044d9166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC Score: 0.6103\n",
      "Mean Reciprocal Rank (MRR): 0.0001\n",
      "Hits@1: 0.0000\n",
      "Hits@3: 0.0000\n",
      "Hits@10: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Evaluate link prediction performance\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_embeddings = model(node_features_tensor, edge_index)\n",
    "    \n",
    "    # Test positive edges\n",
    "    test_pos_scores = (test_embeddings[edges_test[0]] * test_embeddings[edges_test[1]]).sum(dim=1)\n",
    "    \n",
    "    # Test negative edges\n",
    "    test_neg_edges = generate_negative_samples(edges_test, len(nodes), edges_test.size(1))\n",
    "    test_neg_scores = (test_embeddings[test_neg_edges[0]] * test_embeddings[test_neg_edges[1]]).sum(dim=1)\n",
    "    \n",
    "    # Compute probability scores\n",
    "    y_true = torch.cat([torch.ones(test_pos_scores.size(0)), torch.zeros(test_neg_scores.size(0))])\n",
    "    y_pred = torch.cat([test_pos_scores, test_neg_scores]).sigmoid()  # Apply sigmoid\n",
    "\n",
    "    # Compute AUC-ROC\n",
    "    auc_roc = roc_auc_score(y_true.cpu().numpy(), y_pred.cpu().numpy())\n",
    "    print(f\"AUC-ROC Score: {auc_roc:.4f}\")\n",
    "\n",
    "    # Compute Mean Reciprocal Rank (MRR)\n",
    "    ranks = torch.argsort(torch.argsort(-y_pred))\n",
    "    mrr = (1 / (1 + ranks)).mean().item()\n",
    "    print(f\"Mean Reciprocal Rank (MRR): {mrr:.4f}\")\n",
    "\n",
    "    # Compute Hits@K\n",
    "    def compute_hits_at_k(scores, k):\n",
    "        return (scores.topk(k)[1] < k).float().mean().item()\n",
    "\n",
    "    hits_at_1 = compute_hits_at_k(y_pred, 1)\n",
    "    hits_at_3 = compute_hits_at_k(y_pred, 3)\n",
    "    hits_at_10 = compute_hits_at_k(y_pred, 10)\n",
    "\n",
    "    print(f\"Hits@1: {hits_at_1:.4f}\")\n",
    "    print(f\"Hits@3: {hits_at_3:.4f}\")\n",
    "    print(f\"Hits@10: {hits_at_10:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e17f3-9796-47df-9bd4-79d2411a461b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ab2d5-7d2d-4425-a4fb-de86b3958170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "e8397583-a4a6-4e73-a52f-8f90d25fed9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Triples: 2906769\n",
      "Summarized Triples: 872030\n",
      "Summarized OWL file saved as: enriched_ppio_ontology_final_54_summarized.owl\n"
     ]
    }
   ],
   "source": [
    "import rdflib\n",
    "import random\n",
    "\n",
    "def summarize_owl_file(input_owl, output_owl, sample_ratio=0.3, min_triples=50):\n",
    "    \"\"\"\n",
    "    Summarizes an OWL file by randomly sampling a subset of triples while preserving key entities and relationships.\n",
    "    \n",
    "    Parameters:\n",
    "    - input_owl (str): Path to the input OWL file.\n",
    "    - output_owl (str): Path to save the summarized OWL file.\n",
    "    - sample_ratio (float): Percentage of triples to retain (default 30%).\n",
    "    - min_triples (int): Minimum number of triples to retain (default 50).\n",
    "    \"\"\"\n",
    "    # Load the OWL file\n",
    "    graph = rdflib.Graph()\n",
    "    graph.parse(input_owl, format=\"xml\")\n",
    "\n",
    "    # Extract all triples\n",
    "    all_triples = list(graph)\n",
    "\n",
    "    # Determine number of triples to retain\n",
    "    num_triples_to_keep = max(int(len(all_triples) * sample_ratio), min_triples)\n",
    "    \n",
    "    # Randomly sample triples\n",
    "    sampled_triples = random.sample(all_triples, min(num_triples_to_keep, len(all_triples)))\n",
    "\n",
    "    # Create a new graph and add the sampled triples\n",
    "    summarized_graph = rdflib.Graph()\n",
    "    for triple in sampled_triples:\n",
    "        summarized_graph.add(triple)\n",
    "\n",
    "    # Save the summarized OWL file\n",
    "    summarized_graph.serialize(destination=output_owl, format=\"xml\")\n",
    "\n",
    "    print(f\"Original Triples: {len(all_triples)}\")\n",
    "    print(f\"Summarized Triples: {len(sampled_triples)}\")\n",
    "    print(f\"Summarized OWL file saved as: {output_owl}\")\n",
    "\n",
    "# Example usage\n",
    "input_owl_file = \"enriched_ppio_ontology_final_54_small.owl\"  # Replace with your actual OWL file\n",
    "output_owl_file = \"enriched_ppio_ontology_final_54_summarized.owl\"\n",
    "\n",
    "summarize_owl_file(input_owl_file, output_owl_file, sample_ratio=0.3, min_triples=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa42a9b4-c370-4407-91ee-dff341c640c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515cb5de-17ca-4248-bdfb-5b63d83aca24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af66ce08-33a0-4acf-868e-f0f97d4f6f3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Cannot find DGL C++ graphbolt library at /opt/homebrew/Cellar/jupyterlab/4.3.1_1/libexec/lib/python3.12/site-packages/dgl/graphbolt/libgraphbolt_pytorch_2.5.1.dylib",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdgl\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdgl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RelGraphConv\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.1_1/libexec/lib/python3.12/site-packages/dgl/__init__.py:16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enable_verbose_logging  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend_name, load_backend  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     container,\n\u001b[1;32m     18\u001b[0m     cuda,\n\u001b[1;32m     19\u001b[0m     dataloading,\n\u001b[1;32m     20\u001b[0m     function,\n\u001b[1;32m     21\u001b[0m     ops,\n\u001b[1;32m     22\u001b[0m     random,\n\u001b[1;32m     23\u001b[0m     sampling,\n\u001b[1;32m     24\u001b[0m     storages,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ffi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__, DGLError\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ffi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     extract_ext_funcs,\n\u001b[1;32m     29\u001b[0m     get_global_func,\n\u001b[1;32m     30\u001b[0m     list_global_func_names,\n\u001b[1;32m     31\u001b[0m     register_func,\n\u001b[1;32m     32\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.1_1/libexec/lib/python3.12/site-packages/dgl/dataloading/__init__.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m F\u001b[38;5;241m.\u001b[39mget_preferred_backend() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspot_target\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_dataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.1_1/libexec/lib/python3.12/site-packages/dgl/dataloading/dataloader.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m batch \u001b[38;5;28;01mas\u001b[39;00m batch_graphs\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPUCache\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistGraph\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyFeature\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mheterograph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DGLGraph\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.1_1/libexec/lib/python3.12/site-packages/dgl/distributed/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_context\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exit_client, initialize\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_dataloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistDataLoader\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistGraph, DistGraphServer, edge_split, node_split\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdist_tensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistTensor\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_partition_book\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphPartitionBook, PartitionPolicy\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.1_1/libexec/lib/python3.12/site-packages/dgl/distributed/dist_graph.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MutableMapping\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m F, graphbolt \u001b[38;5;28;01mas\u001b[39;00m gb, heterograph_index\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_ffi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mndarray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m empty_shared_mem\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ALL, DGLError, EID, ETYPE, is_all, NID\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.1_1/libexec/lib/python3.12/site-packages/dgl/graphbolt/__init__.py:36\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=W0703\u001b[39;00m\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot load Graphbolt C++ library\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m \u001b[43mload_graphbolt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# pylint: disable=wrong-import-position\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/4.3.1_1/libexec/lib/python3.12/site-packages/dgl/graphbolt/__init__.py:26\u001b[0m, in \u001b[0;36mload_graphbolt\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraphbolt\u001b[39m\u001b[38;5;124m\"\u001b[39m, basename)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find DGL C++ graphbolt library at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m     )\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m     torch\u001b[38;5;241m.\u001b[39mclasses\u001b[38;5;241m.\u001b[39mload_library(path)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Cannot find DGL C++ graphbolt library at /opt/homebrew/Cellar/jupyterlab/4.3.1_1/libexec/lib/python3.12/site-packages/dgl/graphbolt/libgraphbolt_pytorch_2.5.1.dylib"
     ]
    }
   ],
   "source": [
    "import rdflib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import dgl\n",
    "from dgl.nn import RelGraphConv\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Step 1: Load OWL File and Extract Triples\n",
    "def load_graph_from_owl(file_path, relations_of_interest):\n",
    "    g = rdflib.Graph()\n",
    "    g.parse(file_path, format=\"xml\")\n",
    "    \n",
    "    triples = []\n",
    "    nodes = set()\n",
    "    \n",
    "    for subj, pred, obj in g:\n",
    "        pred_short = str(pred).split(\"/\")[-1]  # Extract relation name\n",
    "        if pred_short in relations_of_interest:\n",
    "            triples.append((str(subj), pred_short, str(obj)))\n",
    "            nodes.add(str(subj))\n",
    "            nodes.add(str(obj))\n",
    "    \n",
    "    return triples, list(nodes)\n",
    "\n",
    "# Step 2: Convert to Numeric ID Mappings\n",
    "def build_mappings(triples, nodes):\n",
    "    node2id = {n: i for i, n in enumerate(nodes)}\n",
    "    relation2id = {r: i for i, r in enumerate(set([t[1] for t in triples]))}\n",
    "    \n",
    "    edge_list = [(node2id[s], node2id[o], relation2id[r]) for s, r, o in triples]\n",
    "    return node2id, relation2id, edge_list\n",
    "\n",
    "# Step 3: Create DGL Graph\n",
    "def build_dgl_graph(edge_list, num_nodes, num_relations):\n",
    "    src, dst, rel = zip(*edge_list)\n",
    "    g = dgl.graph((torch.tensor(src), torch.tensor(dst)), num_nodes=num_nodes)\n",
    "    g.edata['etype'] = torch.tensor(rel)\n",
    "    return g\n",
    "\n",
    "# Step 4: Define R-GCN Model\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, num_nodes, num_relations, hidden_dim, num_layers):\n",
    "        super(RGCN, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_nodes, hidden_dim)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [RelGraphConv(hidden_dim, hidden_dim, num_relations, \"basis\", num_bases=5) for _ in range(num_layers)]\n",
    "        )\n",
    "    \n",
    "    def forward(self, g):\n",
    "        h = self.embedding.weight\n",
    "        for layer in self.layers:\n",
    "            h = layer(g, h, g.edata['etype'])\n",
    "        return h\n",
    "\n",
    "# Step 5: Train Model\n",
    "def train_model(graph, num_nodes, num_relations, edge_list):\n",
    "    model = RGCN(num_nodes, num_relations, hidden_dim=16, num_layers=2)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    loss_fn = nn.MSELoss()\n",
    "    \n",
    "    for epoch in range(50):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(graph)\n",
    "        loss = loss_fn(embeddings[torch.tensor([e[0] for e in edge_list])], embeddings[torch.tensor([e[1] for e in edge_list])])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "    \n",
    "    return model, embeddings\n",
    "\n",
    "# Load and Prepare Data\n",
    "owl_file = \"enriched_ppio_ontology_final_54_small.owl.owl\"\n",
    "relations_of_interest = [\"hasSample\", \"hasGeneExpression\", \"isAssociatedWithPathway\", \"isAssociatedWith\"]\n",
    "triples, nodes = load_graph_from_owl(owl_file, relations_of_interest)\n",
    "node2id, relation2id, edge_list = build_mappings(triples, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8a8f58-4a35-41d2-bf1e-c18d3ea8f5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4c74f14-43a4-49c2-b88b-d5398478c471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'dgl'...\n",
      "remote: Enumerating objects: 57222, done.\u001b[K\n",
      "remote: Counting objects: 100% (6576/6576), done.\u001b[K Counting objects: 100% (6576/6576)\u001b[K\n",
      "remote: Compressing objects: 100% (779/779), done.\u001b[K Compressing objects:  20% (156/779)\u001b[Kremote: Compressing objects:  25% (195/779)\u001b[Kremote: Compressing objects:  27% (211/779)\u001b[K\n",
      "Receiving objects:  98% (56078/57222), 25.22 MiB | 12.17 MiB/s57222)Receiving objects:   2% (1145/57222)Receiving objects:   5% (2862/57222)Receiving objects:   7% (4006/57222)Receiving objects:   8% (4578/57222)Receiving objects:  12% (6867/57222)Receiving objects:  13% (7439/57222), 5.19 MiB | 9.09 MiB/sReceiving objects:  15% (8584/57222), 5.19 MiB | 9.09 MiB/sReceiving objects:  17% (9728/57222), 5.19 MiB | 9.09 MiB/sReceiving objects:  18% (10300/57222), 5.19 MiB | 9.09 MiB/sReceiving objects:  22% (12708/57222), 5.19 MiB | 9.09 MiB/sReceiving objects:  25% (14306/57222), 11.84 MiB | 11.04 MiB/sReceiving objects:  35% (20028/57222), 11.84 MiB | 11.04 MiB/sReceiving objects:  37% (21173/57222), 11.84 MiB | 11.04 MiB/sReceiving objects:  39% (22317/57222), 11.84 MiB | 11.04 MiB/sReceiving objects:  41% (23462/57222), 11.84 MiB | 11.04 MiB/sReceiving objects:  43% (24606/57222), 11.84 MiB | 11.04 MiB/sReceiving objects:  46% (26323/57222), 11.84 MiB | 11.04 MiB/sReceiving objects:  48% (27467/57222), 11.84 MiB | 11.04 MiB/sReceiving objects:  50% (28611/57222), 11.84 MiB | 11.04 MiB/sReceiving objects:  53% (30328/57222), 19.37 MiB | 12.33 MiB/sReceiving objects:  55% (31473/57222), 19.37 MiB | 12.33 MiB/sReceiving objects:  59% (33761/57222), 19.37 MiB | 12.33 MiB/sReceiving objects:  64% (36623/57222), 19.37 MiB | 12.33 MiB/sReceiving objects:  68% (38911/57222), 19.37 MiB | 12.33 MiB/sReceiving objects:  70% (40056/57222), 19.37 MiB | 12.33 MiB/sReceiving objects:  77% (44061/57222), 19.37 MiB | 12.33 MiB/sReceiving objects:  78% (44634/57222), 19.37 MiB | 12.33 MiB/sReceiving objects:  83% (47495/57222), 19.37 MiB | 12.33 MiB/sReceiving objects:  86% (49211/57222), 25.22 MiB | 12.17 MiB/sReceiving objects:  87% (49784/57222), 25.22 MiB | 12.17 MiB/sReceiving objects:  89% (50928/57222), 25.22 MiB | 12.17 MiB/sReceiving objects:  96% (54934/57222), 25.22 MiB | 12.17 MiB/sReceiving objects:  97% (55506/57222), 25.22 MiB | 12.17 MiB/sReceiving objects:  99% (56650/57222), 29.11 MiB | 11.32 MiB/sremote: Total 57222 (delta 6257), reused 5797 (delta 5797), pack-reused 50646 (from 3)\u001b[K\n",
      "Receiving objects: 100% (57222/57222), 29.97 MiB | 11.13 MiB/s, done.\n",
      "Resolving deltas: 100% (38974/38974), done. deltas:   2% (780/38974)Resolving deltas:   8% (3118/38974)Resolving deltas:  16% (6236/38974)Resolving deltas:  25% (9744/38974)Resolving deltas:  42% (16370/38974)Resolving deltas:  53% (20657/38974)Resolving deltas:  69% (26893/38974)Resolving deltas:  95% (37026/38974)\n",
      "Submodule 'third_party/GKlib' (https://github.com/KarypisLab/GKlib.git) registered for path 'third_party/GKlib'\n",
      "Submodule 'third_party/METIS' (https://github.com/KarypisLab/METIS.git) registered for path 'third_party/METIS'\n",
      "Submodule 'third_party/cccl' (https://github.com/NVIDIA/cccl.git) registered for path 'third_party/cccl'\n",
      "Submodule 'third_party/cuco' (https://github.com/NVIDIA/cuCollections.git) registered for path 'third_party/cuco'\n",
      "Submodule 'third_party/dlpack' (https://github.com/dmlc/dlpack.git) registered for path 'third_party/dlpack'\n",
      "Submodule 'third_party/dmlc-core' (https://github.com/dmlc/dmlc-core.git) registered for path 'third_party/dmlc-core'\n",
      "Submodule 'third_party/googletest' (https://github.com/google/googletest.git) registered for path 'third_party/googletest'\n",
      "Submodule 'third_party/liburing' (https://github.com/axboe/liburing.git) registered for path 'third_party/liburing'\n",
      "Submodule 'third_party/libxsmm' (https://github.com/hfp/libxsmm.git) registered for path 'third_party/libxsmm'\n",
      "Submodule 'third_party/nanoflann' (https://github.com/jlblancoc/nanoflann) registered for path 'third_party/nanoflann'\n",
      "Submodule 'third_party/pcg' (https://github.com/imneme/pcg-cpp.git) registered for path 'third_party/pcg'\n",
      "Submodule 'third_party/taskflow' (https://github.com/taskflow/taskflow.git) registered for path 'third_party/taskflow'\n",
      "Submodule 'third_party/tsl_robin_map' (https://github.com/Tessil/robin-map.git) registered for path 'third_party/tsl_robin_map'\n",
      "Cloning into '/Users/pratistha99/Desktop/BDMA/CS/subjects/BDRP/dgl/third_party/GKlib'...\n",
      "remote: Enumerating objects: 182, done.        \n",
      "remote: Counting objects: 100% (79/79), done.        \n",
      "remote: Compressing objects: 100% (27/27), done.        \n",
      "remote: Total 182 (delta 58), reused 52 (delta 52), pack-reused 103 (from 1)        \n",
      "Receiving objects: 100% (182/182), 234.50 KiB | 3.30 MiB/s, done.\n",
      "Resolving deltas: 100% (77/77), done.\n",
      "Cloning into '/Users/pratistha99/Desktop/BDMA/CS/subjects/BDRP/dgl/third_party/METIS'...\n",
      "remote: Enumerating objects: 474, done.        \n",
      "remote: Counting objects: 100% (190/190), done.        \n",
      "remote: Compressing objects: 100% (63/63), done.         Compressing objects:  28% (18/63)        \n",
      "remote: Total 474 (delta 144), reused 127 (delta 127), pack-reused 284 (from 1)         (408/474)\n",
      "Receiving objects: 100% (474/474), 4.75 MiB | 11.21 MiB/s, done.\n",
      "Resolving deltas: 100% (265/265), done.\n",
      "Cloning into '/Users/pratistha99/Desktop/BDMA/CS/subjects/BDRP/dgl/third_party/cccl'...\n",
      "remote: Enumerating objects: 194322, done.        \n",
      "remote: Counting objects: 100% (2124/2124), done.        \n",
      "remote: Compressing objects: 100% (962/962), done.        Compressing objects:  11% (106/962)        remote: Compressing objects:  33% (318/962)        \n",
      "Receiving objects:  90% (174890/194322), 63.71 MiB | 4.36 MiB/s/194322)Receiving objects:   2% (3887/194322)Receiving objects:   3% (5830/194322)Receiving objects:   4% (7773/194322)Receiving objects:   5% (9717/194322)Receiving objects:   6% (11660/194322)Receiving objects:   7% (13603/194322), 4.86 MiB | 9.49 MiB/sReceiving objects:   8% (15546/194322), 4.86 MiB | 9.49 MiB/sReceiving objects:   9% (17489/194322), 4.86 MiB | 9.49 MiB/sReceiving objects:  10% (19433/194322), 10.21 MiB | 10.06 MiB/sReceiving objects:  11% (21376/194322), 10.21 MiB | 10.06 MiB/sReceiving objects:  12% (23319/194322), 10.21 MiB | 10.06 MiB/sReceiving objects:  13% (25262/194322), 14.60 MiB | 9.64 MiB/s Receiving objects:  14% (27206/194322), 14.60 MiB | 9.64 MiB/sReceiving objects:  15% (29149/194322), 14.60 MiB | 9.64 MiB/sReceiving objects:  16% (31092/194322), 14.60 MiB | 9.64 MiB/sReceiving objects:  17% (33035/194322), 14.60 MiB | 9.64 MiB/sReceiving objects:  17% (34421/194322), 14.60 MiB | 9.64 MiB/sReceiving objects:  19% (36922/194322), 19.32 MiB | 9.59 MiB/sReceiving objects:  20% (38865/194322), 19.32 MiB | 9.59 MiB/sReceiving objects:  21% (40808/194322), 19.32 MiB | 9.59 MiB/sReceiving objects:  22% (42751/194322), 19.32 MiB | 9.59 MiB/sReceiving objects:  23% (44695/194322), 22.52 MiB | 8.96 MiB/sReceiving objects:  24% (46638/194322), 22.52 MiB | 8.96 MiB/sReceiving objects:  25% (48581/194322), 22.52 MiB | 8.96 MiB/sReceiving objects:  25% (49528/194322), 22.52 MiB | 8.96 MiB/sReceiving objects:  26% (50524/194322), 25.90 MiB | 8.57 MiB/sReceiving objects:  27% (52467/194322), 25.90 MiB | 8.57 MiB/sReceiving objects:  28% (54411/194322), 25.90 MiB | 8.57 MiB/sReceiving objects:  29% (56354/194322), 25.90 MiB | 8.57 MiB/sReceiving objects:  30% (58297/194322), 25.90 MiB | 8.57 MiB/sReceiving objects:  31% (60240/194322), 25.90 MiB | 8.57 MiB/sReceiving objects:  32% (62184/194322), 29.15 MiB | 8.25 MiB/sReceiving objects:  33% (64127/194322), 29.15 MiB | 8.25 MiB/sReceiving objects:  34% (66070/194322), 29.15 MiB | 8.25 MiB/sReceiving objects:  35% (68013/194322), 29.15 MiB | 8.25 MiB/sReceiving objects:  35% (69039/194322), 29.15 MiB | 8.25 MiB/sReceiving objects:  36% (69956/194322), 32.09 MiB | 7.96 MiB/sReceiving objects:  37% (71900/194322), 32.09 MiB | 7.96 MiB/sReceiving objects:  38% (73843/194322), 32.09 MiB | 7.96 MiB/sReceiving objects:  39% (75786/194322), 32.09 MiB | 7.96 MiB/sReceiving objects:  40% (77729/194322), 34.76 MiB | 7.67 MiB/sReceiving objects:  41% (79673/194322), 34.76 MiB | 7.67 MiB/sReceiving objects:  42% (81616/194322), 34.76 MiB | 7.67 MiB/sReceiving objects:  44% (85502/194322), 34.76 MiB | 7.67 MiB/sReceiving objects:  44% (87253/194322), 34.76 MiB | 7.67 MiB/sReceiving objects:  46% (89389/194322), 37.48 MiB | 7.22 MiB/sReceiving objects:  47% (91332/194322), 37.48 MiB | 7.22 MiB/sReceiving objects:  48% (93275/194322), 37.48 MiB | 7.22 MiB/sReceiving objects:  49% (95218/194322), 37.48 MiB | 7.22 MiB/sReceiving objects:  50% (97161/194322), 40.55 MiB | 6.71 MiB/sReceiving objects:  51% (99105/194322), 40.55 MiB | 6.71 MiB/sReceiving objects:  52% (101048/194322), 40.55 MiB | 6.71 MiB/sReceiving objects:  53% (102991/194322), 40.55 MiB | 6.71 MiB/sReceiving objects:  53% (103891/194322), 40.55 MiB | 6.71 MiB/sReceiving objects:  55% (106878/194322), 44.04 MiB | 6.50 MiB/sReceiving objects:  56% (108821/194322), 44.04 MiB | 6.50 MiB/sReceiving objects:  57% (110764/194322), 44.04 MiB | 6.50 MiB/sReceiving objects:  59% (114650/194322), 44.04 MiB | 6.50 MiB/sReceiving objects:  60% (116594/194322), 44.04 MiB | 6.50 MiB/sReceiving objects:  61% (118537/194322), 44.04 MiB | 6.50 MiB/sReceiving objects:  63% (122423/194322), 44.04 MiB | 6.50 MiB/sReceiving objects:  64% (124367/194322), 44.04 MiB | 6.50 MiB/sReceiving objects:  65% (126310/194322), 46.88 MiB | 6.09 MiB/sReceiving objects:  65% (127631/194322), 46.88 MiB | 6.09 MiB/sReceiving objects:  66% (128253/194322), 49.04 MiB | 5.86 MiB/sReceiving objects:  67% (130196/194322), 49.04 MiB | 5.86 MiB/sReceiving objects:  67% (131605/194322), 50.44 MiB | 5.42 MiB/sReceiving objects:  68% (132139/194322), 52.26 MiB | 5.12 MiB/sReceiving objects:  69% (134083/194322), 52.26 MiB | 5.12 MiB/sReceiving objects:  70% (136026/194322), 54.33 MiB | 4.92 MiB/sReceiving objects:  71% (137969/194322), 54.33 MiB | 4.92 MiB/sReceiving objects:  71% (139091/194322), 54.33 MiB | 4.92 MiB/sReceiving objects:  72% (139912/194322), 56.80 MiB | 4.88 MiB/sReceiving objects:  73% (141856/194322), 56.80 MiB | 4.88 MiB/sReceiving objects:  74% (143799/194322), 56.80 MiB | 4.88 MiB/sReceiving objects:  75% (145742/194322), 59.59 MiB | 4.89 MiB/sReceiving objects:  76% (147685/194322), 59.59 MiB | 4.89 MiB/sReceiving objects:  76% (149562/194322), 59.59 MiB | 4.89 MiB/sReceiving objects:  78% (151572/194322), 61.71 MiB | 4.68 MiB/sReceiving objects:  79% (153515/194322), 61.71 MiB | 4.68 MiB/sReceiving objects:  80% (155458/194322), 61.71 MiB | 4.68 MiB/sReceiving objects:  81% (157401/194322), 61.71 MiB | 4.68 MiB/sReceiving objects:  82% (159345/194322), 63.71 MiB | 4.36 MiB/sReceiving objects:  83% (161288/194322), 63.71 MiB | 4.36 MiB/sReceiving objects:  84% (163231/194322), 63.71 MiB | 4.36 MiB/sReceiving objects:  85% (165174/194322), 63.71 MiB | 4.36 MiB/sReceiving objects:  86% (167117/194322), 63.71 MiB | 4.36 MiB/sReceiving objects:  87% (169061/194322), 63.71 MiB | 4.36 MiB/sReceiving objects:  88% (171004/194322), 63.71 MiB | 4.36 MiB/sReceiving objects:  89% (172947/194322), 63.71 MiB | 4.36 MiB/sReceiving objects:  89% (174487/194322), 63.71 MiB | 4.36 MiB/sReceiving objects:  91% (176834/194322), 66.14 MiB | 4.27 MiB/sReceiving objects:  92% (178777/194322), 66.14 MiB | 4.27 MiB/sReceiving objects:  93% (180720/194322), 66.14 MiB | 4.27 MiB/sReceiving objects:  94% (182663/194322), 66.14 MiB | 4.27 MiB/sReceiving objects:  95% (184606/194322), 66.14 MiB | 4.27 MiB/sReceiving objects:  96% (186550/194322), 66.14 MiB | 4.27 MiB/sReceiving objects:  97% (188493/194322), 66.14 MiB | 4.27 MiB/sReceiving objects:  98% (190436/194322), 68.81 MiB | 4.38 MiB/sReceiving objects:  99% (192379/194322), 68.81 MiB | 4.38 MiB/sReceiving objects:  99% (194037/194322), 68.81 MiB | 4.38 MiB/sremote: Total 194322 (delta 1807), reused 1173 (delta 1159), pack-reused 192198 (from 2)        \n",
      "Receiving objects: 100% (194322/194322), 71.07 MiB | 5.89 MiB/s, done.\n",
      "Resolving deltas: 100% (150422/150422), done. deltas:   2% (3010/150422)Resolving deltas:   3% (4513/150422)Resolving deltas:   6% (9026/150422)Resolving deltas:   8% (12034/150422)Resolving deltas:  11% (16547/150422)Resolving deltas:  16% (24068/150422)Resolving deltas:  20% (30085/150422)Resolving deltas:  23% (34598/150422)Resolving deltas:  27% (40615/150422)Resolving deltas:  30% (45127/150422)Resolving deltas:  32% (48136/150422)Resolving deltas:  35% (52649/150422)Resolving deltas:  39% (58665/150422)Resolving deltas:  43% (64682/150422)Resolving deltas:  48% (72203/150422)Resolving deltas:  52% (78220/150422)Resolving deltas:  56% (84237/150422)Resolving deltas:  61% (91758/150422)Resolving deltas:  68% (102287/150422)Resolving deltas:  74% (111313/150422)Resolving deltas:  80% (120338/150422)Resolving deltas:  82% (123347/150422)Resolving deltas:  84% (126355/150422)Resolving deltas:  87% (130868/150422)Resolving deltas:  90% (135380/150422)Resolving deltas:  95% (142901/150422)Resolving deltas: 100% (150422/150422)\n",
      "Cloning into '/Users/pratistha99/Desktop/BDMA/CS/subjects/BDRP/dgl/third_party/cuco'...\n",
      "remote: Enumerating objects: 11705, done.        \n",
      "remote: Counting objects: 100% (188/188), done.        \n",
      "remote: Compressing objects: 100% (147/147), done.        Compressing objects:  50% (74/147)        \n",
      "Receiving objects:  99% (11588/11705), 5.66 MiB | 11.28 MiB/s35/11705)Receiving objects:   8% (937/11705)Receiving objects:  16% (1873/11705)Receiving objects:  17% (1990/11705)Receiving objects:  23% (2693/11705)Receiving objects:  59% (6906/11705)Receiving objects:  66% (7726/11705)Receiving objects:  77% (9013/11705)Receiving objects:  80% (9364/11705)Receiving objects:  97% (11354/11705), 5.66 MiB | 11.28 MiB/sremote: Total 11705 (delta 121), reused 43 (delta 38), pack-reused 11517 (from 3)        \n",
      "Receiving objects: 100% (11705/11705), 6.93 MiB | 11.33 MiB/s, done.\n",
      "Resolving deltas: 100% (7680/7680), done.g deltas:  10% (768/7680)Resolving deltas:  18% (1383/7680)Resolving deltas:  97% (7450/7680)\n",
      "Cloning into '/Users/pratistha99/Desktop/BDMA/CS/subjects/BDRP/dgl/third_party/dlpack'...\n",
      "remote: Enumerating objects: 517, done.        \n",
      "remote: Counting objects: 100% (168/168), done.        % (34/168)        \n",
      "remote: Compressing objects: 100% (86/86), done.        \n",
      "Receiving objects:  99% (512/517)eceiving objects:   4% (21/517)Receiving objects:   7% (37/517)remote: Total 517 (delta 96), reused 123 (delta 73), pack-reused 349 (from 1)        \n",
      "Receiving objects: 100% (517/517), 2.15 MiB | 10.44 MiB/s, done.\n",
      "Resolving deltas: 100% (184/184), done.\n",
      "Cloning into '/Users/pratistha99/Desktop/BDMA/CS/subjects/BDRP/dgl/third_party/dmlc-core'...\n",
      "remote: Enumerating objects: 6358, done.        \n",
      "remote: Counting objects: 100% (83/83), done.        \n",
      "remote: Compressing objects: 100% (41/41), done.        \n",
      "remote: Total 6358 (delta 58), reused 42 (delta 42), pack-reused 6275 (from 2)          23% (1463/6358)Receiving objects:  72% (4578/6358)\n",
      "Receiving objects: 100% (6358/6358), 1.73 MiB | 9.40 MiB/s, done.\n",
      "Resolving deltas: 100% (3845/3845), done. deltas:   2% (77/3845)\n",
      "Cloning into '/Users/pratistha99/Desktop/BDMA/CS/subjects/BDRP/dgl/third_party/googletest'...\n",
      "remote: Enumerating objects: 27769, done.        \n",
      "remote: Counting objects: 100% (77/77), done.        Counting objects:  10% (8/77)        )        \n",
      "remote: Compressing objects: 100% (58/58), done.        \n",
      "Receiving objects:  99% (27492/27769), 10.86 MiB | 10.81 MiB/s27769)Receiving objects:   6% (1667/27769)Receiving objects:  11% (3055/27769)Receiving objects:  16% (4444/27769)Receiving objects:  17% (4721/27769)Receiving objects:  19% (5277/27769)Receiving objects:  20% (5554/27769)Receiving objects:  21% (5832/27769)Receiving objects:  25% (6943/27769)Receiving objects:  27% (7498/27769), 5.19 MiB | 10.35 MiB/sReceiving objects:  28% (7776/27769), 5.19 MiB | 10.35 MiB/sReceiving objects:  31% (8609/27769), 5.19 MiB | 10.35 MiB/sReceiving objects:  34% (9442/27769), 5.19 MiB | 10.35 MiB/sReceiving objects:  37% (10275/27769), 5.19 MiB | 10.35 MiB/sReceiving objects:  40% (11108/27769), 5.19 MiB | 10.35 MiB/sReceiving objects:  47% (13052/27769), 5.19 MiB | 10.35 MiB/sReceiving objects:  49% (13607/27769), 5.19 MiB | 10.35 MiB/sReceiving objects:  50% (13885/27769), 5.19 MiB | 10.35 MiB/sReceiving objects:  54% (15224/27769), 10.86 MiB | 10.81 MiB/sReceiving objects:  66% (18328/27769), 10.86 MiB | 10.81 MiB/sReceiving objects:  83% (23049/27769), 10.86 MiB | 10.81 MiB/sremote: Total 27769 (delta 40), reused 19 (delta 19), pack-reused 27692 (from 4)        \n",
      "Receiving objects: 100% (27769/27769), 13.32 MiB | 10.60 MiB/s, done.\n",
      "Resolving deltas: 100% (20600/20600), done. deltas:   2% (412/20600)Resolving deltas:   5% (1030/20600)Resolving deltas:  10% (2060/20600)Resolving deltas:  17% (3502/20600)Resolving deltas:  27% (5562/20600)Resolving deltas:  34% (7004/20600)Resolving deltas:  47% (9682/20600)Resolving deltas:  75% (15450/20600)\n",
      "Cloning into '/Users/pratistha99/Desktop/BDMA/CS/subjects/BDRP/dgl/third_party/liburing'...\n",
      "remote: Enumerating objects: 15320, done.        \n",
      "remote: Counting objects: 100% (1489/1489), done.        \n",
      "remote: Compressing objects: 100% (121/121), done.        \n",
      "remote: Total 15320 (delta 1403), reused 1368 (delta 1368), pack-reused 13831 (from 3)        66/15320)Receiving objects:  16% (2452/15320)Receiving objects:  25% (3830/15320)Receiving objects:  46% (7048/15320)Receiving objects:  68% (10418/15320)Receiving objects:  95% (14554/15320)\n",
      "Receiving objects: 100% (15320/15320), 3.45 MiB | 9.83 MiB/s, done.\n",
      "Resolving deltas: 100% (10904/10904), done. deltas:  10% (1091/10904)Resolving deltas:  46% (5016/10904)\n",
      "Cloning into '/Users/pratistha99/Desktop/BDMA/CS/subjects/BDRP/dgl/third_party/libxsmm'...\n",
      "remote: Enumerating objects: 159231, done.        \n",
      "remote: Counting objects: 100% (526/526), done.         Counting objects:  76% (400/526)        \n",
      "remote: Compressing objects: 100% (279/279), done.        Compressing objects:   5% (14/279)        remote: Compressing objects:   8% (23/279)        remote: Compressing objects:   9% (26/279)        remote: Compressing objects:  10% (28/279)        remote: Compressing objects:  11% (31/279)        remote: Compressing objects:  13% (37/279)        remote: Compressing objects:  19% (54/279)        remote: Compressing objects:  24% (67/279)        remote: Compressing objects:  31% (87/279)        remote: Compressing objects:  72% (201/279)        \n",
      "Receiving objects:  99% (157639/159231), 298.97 MiB | 4.00 MiB/s159231)Receiving objects:   2% (3185/159231)Receiving objects:   3% (4777/159231)Receiving objects:   6% (9554/159231)Receiving objects:   7% (11147/159231)Receiving objects:  10% (15924/159231)Receiving objects:  11% (18413/159231), 5.43 MiB | 9.75 MiB/sReceiving objects:  12% (19108/159231), 13.47 MiB | 12.75 MiB/sReceiving objects:  12% (19670/159231), 26.32 MiB | 12.80 MiB/sReceiving objects:  12% (19671/159231), 31.28 MiB | 12.20 MiB/sReceiving objects:  13% (20701/159231), 35.21 MiB | 11.49 MiB/sReceiving objects:  13% (21708/159231), 44.25 MiB | 10.86 MiB/sReceiving objects:  13% (21710/159231), 49.18 MiB | 10.75 MiB/sReceiving objects:  14% (22293/159231), 54.21 MiB | 10.79 MiB/sReceiving objects:  15% (23885/159231), 59.01 MiB | 10.08 MiB/sReceiving objects:  16% (25477/159231), 59.01 MiB | 10.08 MiB/sReceiving objects:  16% (26901/159231), 59.01 MiB | 10.08 MiB/sReceiving objects:  18% (28662/159231), 63.42 MiB | 9.50 MiB/s Receiving objects:  19% (30254/159231), 63.42 MiB | 9.50 MiB/sReceiving objects:  20% (31847/159231), 63.42 MiB | 9.50 MiB/sReceiving objects:  21% (33439/159231), 63.42 MiB | 9.50 MiB/sReceiving objects:  22% (35031/159231), 63.42 MiB | 9.50 MiB/sReceiving objects:  23% (36624/159231), 67.94 MiB | 9.20 MiB/sReceiving objects:  24% (38216/159231), 67.94 MiB | 9.20 MiB/sReceiving objects:  25% (39808/159231), 67.94 MiB | 9.20 MiB/sReceiving objects:  25% (41282/159231), 67.94 MiB | 9.20 MiB/sReceiving objects:  26% (41401/159231), 72.07 MiB | 9.01 MiB/sReceiving objects:  27% (42993/159231), 72.07 MiB | 9.01 MiB/sReceiving objects:  28% (44585/159231), 72.07 MiB | 9.01 MiB/sReceiving objects:  29% (46177/159231), 72.07 MiB | 9.01 MiB/sReceiving objects:  30% (47770/159231), 75.82 MiB | 8.96 MiB/sReceiving objects:  31% (49362/159231), 75.82 MiB | 8.96 MiB/sReceiving objects:  31% (50471/159231), 79.82 MiB | 8.85 MiB/sReceiving objects:  32% (50954/159231), 79.82 MiB | 8.85 MiB/sReceiving objects:  33% (52547/159231), 79.82 MiB | 8.85 MiB/sReceiving objects:  34% (54139/159231), 84.10 MiB | 8.82 MiB/sReceiving objects:  35% (55731/159231), 84.10 MiB | 8.82 MiB/sReceiving objects:  36% (57324/159231), 84.10 MiB | 8.82 MiB/sReceiving objects:  36% (58158/159231), 84.10 MiB | 8.82 MiB/sReceiving objects:  38% (60508/159231), 84.10 MiB | 8.82 MiB/sReceiving objects:  39% (62101/159231), 88.80 MiB | 8.76 MiB/sReceiving objects:  40% (63693/159231), 88.80 MiB | 8.76 MiB/sReceiving objects:  41% (65285/159231), 93.27 MiB | 8.64 MiB/sReceiving objects:  42% (66878/159231), 93.27 MiB | 8.64 MiB/sReceiving objects:  43% (68470/159231), 93.27 MiB | 8.64 MiB/sReceiving objects:  43% (69569/159231), 93.27 MiB | 8.64 MiB/sReceiving objects:  44% (70062/159231), 93.27 MiB | 8.64 MiB/sReceiving objects:  45% (71654/159231), 97.27 MiB | 8.46 MiB/sReceiving objects:  46% (73247/159231), 97.27 MiB | 8.46 MiB/sReceiving objects:  46% (73807/159231), 104.43 MiB | 8.06 MiB/sReceiving objects:  47% (74839/159231), 108.15 MiB | 7.97 MiB/sReceiving objects:  49% (78024/159231), 108.15 MiB | 7.97 MiB/sReceiving objects:  49% (79048/159231), 112.08 MiB | 8.02 MiB/sReceiving objects:  49% (79074/159231), 116.03 MiB | 8.01 MiB/sReceiving objects:  50% (79616/159231), 116.03 MiB | 8.01 MiB/sReceiving objects:  51% (81208/159231), 119.34 MiB | 7.80 MiB/sReceiving objects:  52% (82801/159231), 119.34 MiB | 7.80 MiB/sReceiving objects:  53% (84393/159231), 123.14 MiB | 7.60 MiB/sReceiving objects:  54% (85985/159231), 123.14 MiB | 7.60 MiB/sReceiving objects:  54% (87476/159231), 127.11 MiB | 7.49 MiB/sReceiving objects:  55% (87578/159231), 131.33 MiB | 7.54 MiB/sReceiving objects:  55% (87651/159231), 135.87 MiB | 7.72 MiB/sReceiving objects:  55% (87951/159231), 145.20 MiB | 8.23 MiB/sReceiving objects:  56% (89170/159231), 145.20 MiB | 8.23 MiB/sReceiving objects:  57% (90762/159231), 145.20 MiB | 8.23 MiB/sReceiving objects:  57% (90766/159231), 154.05 MiB | 8.44 MiB/sReceiving objects:  58% (92354/159231), 158.10 MiB | 8.61 MiB/sReceiving objects:  58% (92480/159231), 158.10 MiB | 8.61 MiB/sReceiving objects:  59% (93947/159231), 165.39 MiB | 8.49 MiB/sReceiving objects:  60% (95539/159231), 169.50 MiB | 8.46 MiB/sReceiving objects:  60% (95817/159231), 173.92 MiB | 8.43 MiB/sReceiving objects:  61% (97131/159231), 181.38 MiB | 8.01 MiB/sReceiving objects:  61% (97311/159231), 185.43 MiB | 7.91 MiB/sReceiving objects:  61% (97329/159231), 192.54 MiB | 7.59 MiB/sReceiving objects:  62% (98724/159231), 195.25 MiB | 7.40 MiB/sReceiving objects:  63% (100316/159231), 198.41 MiB | 7.29 MiB/sReceiving objects:  64% (101908/159231), 198.41 MiB | 7.29 MiB/sReceiving objects:  64% (102611/159231), 204.11 MiB | 6.67 MiB/sReceiving objects:  64% (102765/159231), 210.58 MiB | 6.45 MiB/sReceiving objects:  65% (103501/159231), 210.58 MiB | 6.45 MiB/sReceiving objects:  65% (103696/159231), 214.32 MiB | 6.38 MiB/sReceiving objects:  66% (105093/159231), 217.45 MiB | 6.17 MiB/sReceiving objects:  66% (106211/159231), 221.75 MiB | 5.87 MiB/sReceiving objects:  66% (106525/159231), 226.84 MiB | 5.68 MiB/sReceiving objects:  67% (106685/159231), 226.84 MiB | 5.68 MiB/sReceiving objects:  68% (108278/159231), 229.53 MiB | 5.63 MiB/sReceiving objects:  68% (109470/159231), 232.18 MiB | 5.52 MiB/sReceiving objects:  68% (109484/159231), 238.00 MiB | 5.23 MiB/sReceiving objects:  69% (109870/159231), 238.00 MiB | 5.23 MiB/sReceiving objects:  69% (110201/159231), 240.59 MiB | 5.09 MiB/sReceiving objects:  69% (110427/159231), 246.12 MiB | 5.31 MiB/sReceiving objects:  69% (111291/159231), 251.90 MiB | 5.41 MiB/sReceiving objects:  70% (111462/159231), 254.96 MiB | 5.46 MiB/sReceiving objects:  70% (112239/159231), 257.67 MiB | 5.45 MiB/sReceiving objects:  71% (113055/159231), 257.67 MiB | 5.45 MiB/sReceiving objects:  72% (114647/159231), 257.67 MiB | 5.45 MiB/sReceiving objects:  73% (116239/159231), 260.11 MiB | 5.33 MiB/sReceiving objects:  74% (117831/159231), 260.11 MiB | 5.33 MiB/sReceiving objects:  74% (119246/159231), 262.78 MiB | 5.26 MiB/sReceiving objects:  75% (119424/159231), 265.48 MiB | 5.28 MiB/sReceiving objects:  76% (121016/159231), 265.48 MiB | 5.28 MiB/sReceiving objects:  77% (122608/159231), 267.99 MiB | 5.25 MiB/sReceiving objects:  78% (124201/159231), 267.99 MiB | 5.25 MiB/sReceiving objects:  78% (125712/159231), 272.87 MiB | 5.07 MiB/sReceiving objects:  79% (127246/159231), 278.12 MiB | 4.91 MiB/sReceiving objects:  80% (127385/159231), 278.12 MiB | 4.91 MiB/sReceiving objects:  80% (127690/159231), 280.39 MiB | 4.82 MiB/sReceiving objects:  80% (128701/159231), 285.62 MiB | 4.27 MiB/sReceiving objects:  81% (128978/159231), 285.62 MiB | 4.27 MiB/sReceiving objects:  81% (129356/159231), 287.69 MiB | 4.18 MiB/sReceiving objects:  81% (130458/159231), 292.08 MiB | 4.08 MiB/sReceiving objects:  82% (130570/159231), 294.65 MiB | 4.11 MiB/sReceiving objects:  83% (132162/159231), 294.65 MiB | 4.11 MiB/sReceiving objects:  84% (133755/159231), 294.65 MiB | 4.11 MiB/sReceiving objects:  85% (135347/159231), 294.65 MiB | 4.11 MiB/sReceiving objects:  87% (138531/159231), 294.65 MiB | 4.11 MiB/sReceiving objects:  90% (143308/159231), 294.65 MiB | 4.11 MiB/sReceiving objects:  91% (145503/159231), 297.04 MiB | 4.05 MiB/sReceiving objects:  92% (146493/159231), 298.97 MiB | 4.00 MiB/sReceiving objects:  94% (149678/159231), 298.97 MiB | 4.00 MiB/sReceiving objects:  97% (154455/159231), 298.97 MiB | 4.00 MiB/sremote: Total 159231 (delta 445), reused 247 (delta 247), pack-reused 158705 (from 3)        \n",
      "Receiving objects: 100% (159231/159231), 301.09 MiB | 6.88 MiB/s, done.\n",
      "Resolving deltas: 100% (120983/120983), done.ltas:   1% (1210/120983)Resolving deltas:   2% (2420/120983)Resolving deltas:   3% (3630/120983)Resolving deltas:   5% (6050/120983)Resolving deltas:   7% (8469/120983)Resolving deltas:   8% (9679/120983)Resolving deltas:   9% (10889/120983)Resolving deltas:  10% (12099/120983)Resolving deltas:  11% (13309/120983)Resolving deltas:  13% (15728/120983)Resolving deltas:  14% (16938/120983)Resolving deltas:  17% (20568/120983)Resolving deltas:  18% (21777/120983)Resolving deltas:  18% (22007/120983)Resolving deltas:  19% (22987/120983)Resolving deltas:  20% (24197/120983)Resolving deltas:  22% (26617/120983)Resolving deltas:  24% (29036/120983)Resolving deltas:  29% (35086/120983)Resolving deltas:  31% (37505/120983)Resolving deltas:  33% (39925/120983)Resolving deltas:  36% (43554/120983)Resolving deltas:  39% (47184/120983)Resolving deltas:  42% (50813/120983)Resolving deltas:  43% (52023/120983)Resolving deltas:  45% (54443/120983)Resolving deltas:  47% (56864/120983)Resolving deltas:  52% (62912/120983)Resolving deltas:  54% (65331/120983)Resolving deltas:  56% (67751/120983)Resolving deltas:  58% (70171/120983)Resolving deltas:  61% (74490/120983)Resolving deltas:  62% (75010/120983)Resolving deltas:  64% (77430/120983)Resolving deltas:  69% (83479/120983)Resolving deltas:  72% (87108/120983)Resolving deltas:  76% (91949/120983)Resolving deltas:  83% (100416/120983)Resolving deltas:  91% (110095/120983)Resolving deltas: 100% (120983/120983)\n",
      "Cloning into '/Users/pratistha99/Desktop/BDMA/CS/subjects/BDRP/dgl/third_party/nanoflann'...\n",
      "remote: Enumerating objects: 3316, done.        \n",
      "remote: Counting objects: 100% (648/648), done.        \n",
      "remote: Compressing objects: 100% (197/197), done.        \n",
      "remote: Total 3316 (delta 490), reused 460 (delta 447), pack-reused 2668 (from 4)        7% (564/3316)Receiving objects:  22% (730/3316)Receiving objects:  30% (995/3316)Receiving objects:  76% (2521/3316)\n",
      "Receiving objects: 100% (3316/3316), 2.74 MiB | 9.83 MiB/s, done.\n",
      "Resolving deltas: 100% (1838/1838), done.ng deltas:  62% (1140/1838)\n",
      "Cloning into '/Users/pratistha99/Desktop/BDMA/CS/subjects/BDRP/dgl/third_party/pcg'...\n",
      "remote: Enumerating objects: 489, done.        \n",
      "remote: Counting objects: 100% (151/151), done.        \n",
      "remote: Compressing objects: 100% (20/20), done.        \n",
      "remote: Total 489 (delta 140), reused 131 (delta 131), pack-reused 338 (from 1)        0% (343/489)Receiving objects:  86% (421/489)\n",
      "Receiving objects: 100% (489/489), 163.03 KiB | 1.18 MiB/s, done.\n",
      "Resolving deltas: 100% (225/225), done.\n",
      "Cloning into '/Users/pratistha99/Desktop/BDMA/CS/subjects/BDRP/dgl/third_party/taskflow'...\n",
      "remote: Enumerating objects: 48623, done.        \n",
      "remote: Counting objects: 100% (3352/3352), done.        \n",
      "remote: Compressing objects: 100% (946/946), done.        Compressing objects:   4% (38/946)        remote: Compressing objects:  22% (209/946)        remote: Compressing objects:  42% (398/946)        remote: Compressing objects:  67% (634/946)        \n",
      "Receiving objects:  97% (47165/48623), 133.23 MiB | 7.99 MiB/s48623)Receiving objects:   2% (973/48623)Receiving objects:   6% (2918/48623)Receiving objects:   9% (4377/48623)Receiving objects:  10% (4863/48623)Receiving objects:  12% (5835/48623)Receiving objects:  13% (6321/48623)Receiving objects:  14% (6808/48623)Receiving objects:  15% (7294/48623), 6.00 MiB | 11.55 MiB/sReceiving objects:  16% (7780/48623), 6.00 MiB | 11.55 MiB/sReceiving objects:  16% (8043/48623), 12.73 MiB | 12.49 MiB/sReceiving objects:  17% (8266/48623), 19.36 MiB | 12.74 MiB/sReceiving objects:  18% (8753/48623), 19.36 MiB | 12.74 MiB/sReceiving objects:  21% (10211/48623), 19.36 MiB | 12.74 MiB/sReceiving objects:  22% (10698/48623), 19.36 MiB | 12.74 MiB/sReceiving objects:  23% (11184/48623), 19.36 MiB | 12.74 MiB/sReceiving objects:  24% (11670/48623), 19.36 MiB | 12.74 MiB/sReceiving objects:  25% (12370/48623), 26.04 MiB | 12.89 MiB/sReceiving objects:  26% (12642/48623), 32.22 MiB | 12.59 MiB/sReceiving objects:  26% (12776/48623), 37.64 MiB | 12.29 MiB/sReceiving objects:  27% (13129/48623), 37.64 MiB | 12.29 MiB/sReceiving objects:  28% (13615/48623), 37.64 MiB | 12.29 MiB/sReceiving objects:  29% (14101/48623), 37.64 MiB | 12.29 MiB/sReceiving objects:  32% (15560/48623), 37.64 MiB | 12.29 MiB/sReceiving objects:  33% (16046/48623), 37.64 MiB | 12.29 MiB/sReceiving objects:  35% (17019/48623), 37.64 MiB | 12.29 MiB/sReceiving objects:  37% (17991/48623), 43.09 MiB | 12.09 MiB/sReceiving objects:  39% (18963/48623), 43.09 MiB | 12.09 MiB/sReceiving objects:  40% (19684/48623), 43.09 MiB | 12.09 MiB/sReceiving objects:  41% (19936/48623), 48.37 MiB | 11.90 MiB/sReceiving objects:  42% (20422/48623), 48.37 MiB | 11.90 MiB/sReceiving objects:  43% (20908/48623), 48.37 MiB | 11.90 MiB/sReceiving objects:  44% (21395/48623), 48.37 MiB | 11.90 MiB/sReceiving objects:  46% (22367/48623), 52.83 MiB | 11.58 MiB/sReceiving objects:  47% (22853/48623), 52.83 MiB | 11.58 MiB/sReceiving objects:  47% (23301/48623), 52.83 MiB | 11.58 MiB/sReceiving objects:  48% (23414/48623), 62.39 MiB | 9.47 MiB/s Receiving objects:  48% (23415/48623), 69.99 MiB | 8.38 MiB/sReceiving objects:  48% (23657/48623), 74.13 MiB | 8.10 MiB/sReceiving objects:  49% (23826/48623), 78.74 MiB | 7.92 MiB/sReceiving objects:  50% (24312/48623), 78.74 MiB | 7.92 MiB/sReceiving objects:  52% (25284/48623), 83.40 MiB | 7.78 MiB/sReceiving objects:  54% (26257/48623), 83.40 MiB | 7.78 MiB/sReceiving objects:  55% (26743/48623), 83.40 MiB | 7.78 MiB/sReceiving objects:  58% (28202/48623), 83.40 MiB | 7.78 MiB/sReceiving objects:  58% (28540/48623), 83.40 MiB | 7.78 MiB/sReceiving objects:  59% (28688/48623), 87.58 MiB | 7.71 MiB/sReceiving objects:  60% (29174/48623), 87.58 MiB | 7.71 MiB/sReceiving objects:  61% (29661/48623), 90.50 MiB | 7.57 MiB/sReceiving objects:  62% (30147/48623), 90.50 MiB | 7.57 MiB/sReceiving objects:  63% (30633/48623), 90.50 MiB | 7.57 MiB/sReceiving objects:  65% (31605/48623), 93.80 MiB | 7.66 MiB/sReceiving objects:  66% (32092/48623), 93.80 MiB | 7.66 MiB/sReceiving objects:  68% (33064/48623), 93.80 MiB | 7.66 MiB/sReceiving objects:  69% (33550/48623), 93.80 MiB | 7.66 MiB/sReceiving objects:  69% (33602/48623), 100.89 MiB | 7.75 MiB/sReceiving objects:  69% (33602/48623), 108.69 MiB | 7.67 MiB/sReceiving objects:  70% (34037/48623), 108.69 MiB | 7.67 MiB/sReceiving objects:  70% (34325/48623), 112.23 MiB | 7.43 MiB/sReceiving objects:  71% (34523/48623), 116.00 MiB | 7.23 MiB/sReceiving objects:  72% (35009/48623), 116.00 MiB | 7.23 MiB/sReceiving objects:  73% (35495/48623), 116.00 MiB | 7.23 MiB/sReceiving objects:  74% (35982/48623), 116.00 MiB | 7.23 MiB/sReceiving objects:  75% (36468/48623), 120.07 MiB | 7.21 MiB/sReceiving objects:  76% (36954/48623), 120.07 MiB | 7.21 MiB/sReceiving objects:  77% (37440/48623), 120.07 MiB | 7.21 MiB/sReceiving objects:  78% (37926/48623), 120.07 MiB | 7.21 MiB/sReceiving objects:  79% (38413/48623), 120.07 MiB | 7.21 MiB/sReceiving objects:  79% (38590/48623), 124.47 MiB | 7.53 MiB/sReceiving objects:  80% (38899/48623), 124.47 MiB | 7.53 MiB/sReceiving objects:  81% (39385/48623), 124.47 MiB | 7.53 MiB/sReceiving objects:  82% (39871/48623), 124.47 MiB | 7.53 MiB/sReceiving objects:  83% (40358/48623), 128.98 MiB | 7.80 MiB/sReceiving objects:  84% (40844/48623), 128.98 MiB | 7.80 MiB/sReceiving objects:  85% (41330/48623), 128.98 MiB | 7.80 MiB/sReceiving objects:  86% (41816/48623), 128.98 MiB | 7.80 MiB/sReceiving objects:  87% (42303/48623), 128.98 MiB | 7.80 MiB/sReceiving objects:  87% (42776/48623), 128.98 MiB | 7.80 MiB/sReceiving objects:  89% (43275/48623), 133.23 MiB | 7.99 MiB/sReceiving objects:  90% (43761/48623), 133.23 MiB | 7.99 MiB/sReceiving objects:  91% (44247/48623), 133.23 MiB | 7.99 MiB/sReceiving objects:  92% (44734/48623), 133.23 MiB | 7.99 MiB/sReceiving objects:  93% (45220/48623), 133.23 MiB | 7.99 MiB/sReceiving objects:  98% (47651/48623), 133.23 MiB | 7.99 MiB/sReceiving objects:  99% (48137/48623), 133.23 MiB | 7.99 MiB/sremote: Total 48623 (delta 2931), reused 2440 (delta 2406), pack-reused 45271 (from 3)        \n",
      "Receiving objects: 100% (48623/48623), 138.11 MiB | 8.83 MiB/s, done.\n",
      "Resolving deltas: 100% (39115/39115), done.g deltas:   8% (3130/39115)Resolving deltas:  11% (4303/39115)Resolving deltas:  18% (7041/39115)Resolving deltas:  23% (8998/39115)Resolving deltas:  29% (11344/39115)Resolving deltas:  34% (13300/39115)Resolving deltas:  41% (16039/39115)Resolving deltas:  47% (18385/39115)Resolving deltas:  54% (21123/39115)Resolving deltas:  60% (23469/39115)Resolving deltas:  66% (25816/39115)Resolving deltas:  71% (27772/39115)Resolving deltas:  79% (30901/39115)Resolving deltas:  84% (32858/39115)Resolving deltas:  88% (34422/39115)Resolving deltas:  96% (37552/39115)\n",
      "Cloning into '/Users/pratistha99/Desktop/BDMA/CS/subjects/BDRP/dgl/third_party/tsl_robin_map'...\n",
      "remote: Enumerating objects: 1162, done.        \n",
      "remote: Counting objects: 100% (216/216), done.        \n",
      "remote: Compressing objects: 100% (83/83), done.        \n",
      "remote: Total 1162 (delta 142), reused 166 (delta 108), pack-reused 946 (from 1)         (245/1162)Receiving objects:  50% (581/1162)\n",
      "Receiving objects: 100% (1162/1162), 912.36 KiB | 6.52 MiB/s, done.\n",
      "Resolving deltas: 100% (789/789), done.ng deltas:  45% (356/789)\n",
      "Submodule path 'third_party/GKlib': checked out '8bd6bad750b2b0d90800c632cf18e8ee93ad72d7'\n",
      "Submodule path 'third_party/METIS': checked out 'e0f1b88b8efcb24ffa0ec55eabb78fbe61e58ae7'\n",
      "Submodule path 'third_party/cccl': checked out '709ddec37ff87e6087097ed6e49526dac21dcbc9'\n",
      "Submodule path 'third_party/cuco': checked out '4454de4b878f31d41c5b7578fe6ca24bba5ea3f4'\n",
      "Submodule path 'third_party/dlpack': checked out 'e2bdd3bee8cb6501558042633fa59144cc8b7f5f'\n",
      "Submodule path 'third_party/dmlc-core': checked out 'bfad207b448480783a1f428ae3d93d87032d8349'\n",
      "Submodule path 'third_party/googletest': checked out 'f8d7d77c06936315286eb55f8de22cd23c188571'\n",
      "Submodule path 'third_party/liburing': checked out 'f7dcc1ea60819475dffd3a45059e16f04381bee7'\n",
      "remote: Enumerating objects: 275, done.\u001b[K\n",
      "remote: Counting objects: 100% (209/209), done.\u001b[K\n",
      "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
      "remote: Total 275 (delta 185), reused 180 (delta 180), pack-reused 66 (from 1)\u001b[K\n",
      "Receiving objects: 100% (275/275), 127.05 KiB | 7.94 MiB/s, done.\n",
      "Resolving deltas: 100% (188/188), completed with 91 local objects.lving deltas:  55% (104/188)\n",
      "From https://github.com/hfp/libxsmm\n",
      " * branch                80090603e43f6ddc870cc42e1403dd0af07744cc -> FETCH_HEAD\n",
      "Submodule path 'third_party/libxsmm': checked out '80090603e43f6ddc870cc42e1403dd0af07744cc'\n",
      "Submodule path 'third_party/nanoflann': checked out '4c47ca200209550c5628c89803591f8a753c8181'\n",
      "Submodule path 'third_party/pcg': checked out '428802d1a5634f96bcd0705fab379ff0113bcf13'\n",
      "Submodule path 'third_party/taskflow': checked out '7d9e85b6b2e9bf501021f857f2f3cbe43bc37c85'\n",
      "Submodule path 'third_party/tsl_robin_map': checked out '1115dad3ffa0994e3f43b693d9b9cc99944c64c1'\n"
     ]
    }
   ],
   "source": [
    "!git clone --recursive https://github.com/dmlc/dgl.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff04e3d-90b2-4693-b1b3-b6c00273e7ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1cb021-985b-43de-9c32-56c26a01384e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e554ac46-c8e2-4c55-a0ee-921592af96ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mCMake Warning:\n",
      "  Ignoring extra path from command line:\n",
      "\n",
      "   \"..\"\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[0mCMake Error: The source directory \"/Users/pratistha99/Desktop/BDMA/CS/subjects\" does not appear to contain CMakeLists.txt.\n",
      "Specify --help for usage, or press the help button on the CMake GUI.\u001b[0m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22549dfa-fb6f-4c9e-aed4-572e152c42c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9418ed8-75f0-4800-a424-989cfb34fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Graph and Train Model\n",
    "graph = build_dgl_graph(edge_list, num_nodes=len(nodes), num_relations=len(relation2id))\n",
    "model, embeddings = train_model(graph, len(nodes), len(relation2id), edge_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
